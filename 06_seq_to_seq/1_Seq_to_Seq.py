# å¯¼å…¥å¿…è¦çš„åº“
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, Counter
import random
import time

# è®¾ç½®ä¸­æ–‡å­—ä½“ä»¥ä¾¿matplotlibæ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

# è®¾ç½®éšæœºç§å­ä»¥ä¿è¯ç»“æœå¯å¤ç°
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

print("âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸï¼")
print(f"ğŸ”¥ PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"ğŸ¯ è®¾å¤‡: {'GPU' if torch.cuda.is_available() else 'CPU'}")

# åŠ¨æ‰‹å®ç°ï¼šæ„å»ºä¸€ä¸ªSeq2Seqæ¨¡å‹
# 4.1 å‡†å¤‡æ•°æ®ï¼šä½¿ç”¨è‹±ä¸­ç¿»è¯‘æ•°æ®é›†
# ä»cmn.txtæ–‡ä»¶è¯»å–è‹±ä¸­ç¿»è¯‘æ•°æ®é›†
def load_cmn_data(file_path, max_samples=1000):
    """
    ä»cmn.txtæ–‡ä»¶åŠ è½½è‹±ä¸­ç¿»è¯‘æ•°æ®
    Args:
        file_path: cmn.txtæ–‡ä»¶è·¯å¾„
        max_samples: æœ€å¤§æ ·æœ¬æ•°é‡ï¼ˆä¸ºäº†æ¼”ç¤ºï¼Œé™åˆ¶æ•°æ®é‡ï¼‰
    Returns:
        list: è‹±ä¸­å¥å­å¯¹åˆ—è¡¨
    """
    data_pairs = []

    print(f"ğŸ“ æ­£åœ¨åŠ è½½æ•°æ®æ–‡ä»¶: {file_path}")

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        print(f"ğŸ“Š æ–‡ä»¶æ€»è¡Œæ•°: {len(lines):,}")

        for i, line in enumerate(lines[:max_samples]):
            if i % 10000 == 0:
                print(f"   å¤„ç†è¿›åº¦: {i:,}/{min(max_samples, len(lines)):,}")

            # è§£ææ¯ä¸€è¡Œï¼šè‹±æ–‡\tä¸­æ–‡\tç‰ˆæƒä¿¡æ¯
            parts = line.strip().split('\t')
            if len(parts) >= 2:
                en_sentence = parts[0].strip().lower()              # è‹±æ–‡å¥å­ï¼Œè½¬å°å†™
                zh_sentence = parts[1].strip()                      # ä¸­æ–‡å¥å­

                # ç®€å•è¿‡æ»¤ï¼šåªä¿ç•™é•¿åº¦é€‚ä¸­çš„å¥å­
                if len(en_sentence.split()) <= 10 and len(zh_sentence.split()) <= 20:
                    data_pairs.append((en_sentence, zh_sentence))

    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        return []
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return []

    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼å…±åŠ è½½ {len(data_pairs):,} ä¸ªå¥å­å¯¹")
    return data_pairs

# åŠ è½½cmn.txtæ•°æ®
cmn_file_path = "cmn.txt"
raw_data = load_cmn_data(cmn_file_path, max_samples=2000)

print(f"\nğŸ“ æ•°æ®æ ·ä¾‹:")
if raw_data:
    for i, (en, zh) in enumerate(raw_data[:10]):
        print(f"{i + 1:2d}. è‹±æ–‡: '{en}' â†’ ä¸­æ–‡: '{zh}'")

    print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
    en_lengths = [len(sent.split()) for sent, _ in raw_data]
    zh_lengths = [len(sent) for _, sent in raw_data]

    print(f"   è‹±æ–‡å¥å­é•¿åº¦: æœ€çŸ­ {min(en_lengths)}, æœ€é•¿ {max(en_lengths)}, å¹³å‡ {sum(en_lengths)/len(en_lengths):.1f}")
    print(f"   ä¸­æ–‡å¥å­é•¿åº¦: æœ€çŸ­ {min(zh_lengths)}, æœ€é•¿ {max(zh_lengths)}, å¹³å‡ {sum(zh_lengths)/len(zh_lengths):.1f}")
else:
    print("âŒ æœªèƒ½åŠ è½½æ•°æ®ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®é›†")
    # å¤‡ç”¨æ•°æ®é›†ï¼šåŸºç¡€è‹±ä¸­ç¿»è¯‘å¥å­
    raw_data = [
        ("hello", "ä½ å¥½"),
        ("goodbye", "å†è§"),
        ("thank you", "è°¢è°¢"),
        ("how are you", "ä½ å¥½å—"),
        ("good morning", "æ—©ä¸Šå¥½"),
        ("good night", "æ™šå®‰"),
        ("i love you", "æˆ‘çˆ±ä½ "),
        ("what is your name", "ä½ å«ä»€ä¹ˆåå­—"),
        ("nice to meet you", "å¾ˆé«˜å…´è§åˆ°ä½ "),
        ("see you later", "å†è§"),
        ("excuse me", "ä¸å¥½æ„æ€"),
        ("i am sorry", "å¯¹ä¸èµ·"),
        ("yes", "æ˜¯çš„"),
        ("no", "ä¸æ˜¯"),
        ("please", "è¯·"),
        ("where are you from", "ä½ æ¥è‡ªå“ªé‡Œ"),
        ("i am from china", "æˆ‘æ¥è‡ªä¸­å›½"),
        ("do you speak english", "ä½ ä¼šè¯´è‹±è¯­å—"),
        ("i don't understand", "æˆ‘ä¸æ˜ç™½"),
        ("can you help me", "ä½ èƒ½å¸®åŠ©æˆ‘å—"),
        ("i am hungry", "æˆ‘é¥¿äº†"),
        ("i am thirsty", "æˆ‘æ¸´äº†"),
        ("how much is it", "å¤šå°‘é’±"),
        ("where is the bathroom", "æ´—æ‰‹é—´åœ¨å“ªé‡Œ"),
    ]
    print(f"ğŸ“Š å¤‡ç”¨æ•°æ®é›†å¤§å°: {len(raw_data)} ä¸ªå¥å­å¯¹")

# æ„å»ºè¯æ±‡è¡¨ç±» - è¿™æ˜¯NLPä»»åŠ¡çš„åŸºç¡€å·¥å…·
class Vocabulary:
    def __init__(self):
        self.PAD_TOKEN = 'PAD'                  # å¡«å……ç¬¦å·
        self.SOS_TOKEN = 'SOS'                  # å¥å­å¼€å§‹ç¬¦å·
        self.EOS_TOKEN = 'EOS'                  # å¥å­ç»“æŸç¬¦å·
        self.UNK_TOKEN = 'UNK'                  # æœªçŸ¥è¯ç¬¦å·

        # è¯æ±‡è¡¨å­—å…¸ï¼š word -> index
        self.word2idx = {
            self.PAD_TOKEN: 0,
            self.SOS_TOKEN: 1,
            self.EOS_TOKEN: 2,
            self.UNK_TOKEN: 3
        }

        # åå‘å­—å…¸ï¼š index -> word
        self.idx2word = {idx: word for word, idx in self.word2idx.items()}

    def add_word(self, word):
        """å‘è¯æ±‡è¡¨æ·»åŠ æ–°è¯"""
        if word not in self.word2idx:
            idx = len(self.word2idx)
            self.word2idx[word] = idx
            self.idx2word[idx] = word

    def add_sentence(self, sentence):
        """å‘è¯æ±‡è¡¨æ·»åŠ æ•´ä¸ªå¥å­çš„è¯æ±‡"""
        for word in sentence.split():
            self.add_word(word)

    def __len__(self):
        return len(self.word2idx)

    def encode_sentence(self, sentence, add_eos=True):
        """å°†å¥å­è½¬æ¢ä¸ºç´¢å¼•åºåˆ—"""
        indices = []
        for word in sentence.split():
            if word in self.word2idx:
                indices.append(self.word2idx[word])
            else:
                indices.append(self.word2idx[self.UNK_TOKEN])

        if add_eos:
            indices.append(self.word2idx[self.EOS_TOKEN])

        return indices

    def decode_sentence(self, indices):
        """å°†ç´¢å¼•åºåˆ—è½¬æ¢å›å¥å­"""
        words = []
        for idx in indices:
            if idx == self.word2idx[self.EOS_TOKEN]:
                break
            if idx == self.word2idx[self.PAD_TOKEN]:
                continue
            words.append(self.idx2word[idx])
        return ' '.join(words)

# åˆ›å»ºè‹±æ–‡å’Œä¸­æ–‡è¯æ±‡è¡¨
en_vocab = Vocabulary()
zh_vocab = Vocabulary()

# æ„å»ºè¯æ±‡è¡¨
for en_sentence, zh_sentence in raw_data:
    en_vocab.add_sentence(en_sentence)
    # ä¸­æ–‡æŒ‰å­—ç¬¦åˆ†å‰²ï¼ˆæ¯ä¸ªæ±‰å­—ä½œä¸ºä¸€ä¸ªè¯ï¼‰
    zh_words = ' '.join(list(zh_sentence))
    zh_vocab.add_sentence(zh_words)

print(f"ğŸ“š è‹±æ–‡è¯æ±‡è¡¨å¤§å°: {len(en_vocab)}")
print(f"ğŸ“š ä¸­æ–‡è¯æ±‡è¡¨å¤§å°: {len(zh_vocab)}")

# å±•ç¤ºä¸€äº›è¯æ±‡
print(f"\nğŸ”¤ è‹±æ–‡è¯æ±‡ç¤ºä¾‹: {list(en_vocab.word2idx.keys())[:15]}")
print(f"ğŸ”¤ ä¸­æ–‡è¯æ±‡ç¤ºä¾‹: {list(zh_vocab.word2idx.keys())[:15]}")

# ç‰¹æ®Šå¤„ç†ï¼šä¸ºä¸­æ–‡è¯æ±‡è¡¨æ·»åŠ å­—ç¬¦çº§åˆ«çš„ç¼–ç è§£ç æ–¹æ³•
class ChineseVocabulary(Vocabulary):
    def add_sentence(self, sentence):
        """ä¸­æ–‡å¥å­æŒ‰å­—ç¬¦æ·»åŠ åˆ°è¯æ±‡è¡¨"""
        for char in sentence:
            if char.strip():                # å¿½ç•¥ç©ºæ ¼
                self.add_word(char)

    def encode_sentence(self, sentence, add_eos=True):
        """å°†ä¸­æ–‡å¥å­è½¬æ¢ä¸ºå­—ç¬¦ç´¢å¼•åºåˆ—"""
        indices = []
        for char in sentence:
            if char.strip():                # å¿½ç•¥ç©ºæ ¼
                if char in self.word2idx:
                    indices.append(self.word2idx[char])
                else:
                    indices.append(self.word2idx[self.UNK_TOKEN])

        if add_eos:
            indices.append(self.word2idx[self.EOS_TOKEN])

        return indices

    def decode_sentence(self, indices):
        """å°†å­—ç¬¦ç´¢å¼•åºåˆ—è½¬æ¢å›ä¸­æ–‡å¥å­"""
        chars = []
        for idx in indices:
            if idx == self.word2idx[self.EOS_TOKEN]:
                break
            if idx == self.word2idx[self.PAD_TOKEN]:
                continue
            chars.append(self.idx2word[idx])

        return ''.join(chars)

# é‡æ–°åˆ›å»ºä¸­æ–‡è¯æ±‡è¡¨
zh_vocab = ChineseVocabulary()
for en_sentence, zh_sentence in raw_data:
    zh_vocab.add_sentence(zh_sentence)

print(f"\nğŸ“š æ›´æ–°åçš„ä¸­æ–‡è¯æ±‡è¡¨å¤§å°: {len(zh_vocab)}")
print(f"ğŸ”¤ ä¸­æ–‡å­—ç¬¦ç¤ºä¾‹: {list(zh_vocab.word2idx.keys())[:20]}")


# tokenize (åˆ†è¯)
# åˆ›å»ºæ•°æ®é›†ç±»
class TranslationDataset(Dataset):
    def __init__(self, data_pairs, src_vocab, tgt_vocab, max_length=20):
        """
        ç¿»è¯‘æ•°æ®é›†
        Args:
            data_pairs: å¥å­å¯¹åˆ—è¡¨ [(src_sentence, tgt_sentence), ...]
            src_vocab: æºè¯­è¨€è¯æ±‡è¡¨
            tgt_vocab: ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨
            max_length: æœ€å¤§åºåˆ—é•¿åº¦
        """
        self.data_pairs = data_pairs
        self.src_vocab = src_vocab
        self.tgt_vocab = tgt_vocab
        self.max_length = max_length

    def __len__(self):
        return len(self.data_pairs)

    def __getitem__(self, idx):
        src_sentence, tgt_sentence = self.data_pairs[idx]

        # ç¼–ç æºå¥å­
        src_indices = self.src_vocab.encode_sentence(src_sentence, add_eos=True)

        # ç¼–ç ç›®æ ‡å¥å­ï¼ˆç”¨äºè®­ç»ƒçš„è¾“å…¥ï¼Œéœ€è¦æ·»åŠ SOSï¼‰
        tgt_input_indices = [self.tgt_vocab.word2idx[self.tgt_vocab.SOS_TOKEN]] + \
            self.tgt_vocab.encode_sentence(tgt_sentence, add_eos=False)

        # ç¼–ç ç›®æ ‡å¥å­ï¼ˆç”¨äºè®¡ç®—æŸå¤±çš„æ ‡ç­¾ï¼Œéœ€è¦æ·»åŠ EOSï¼‰
        tgt_output_indices = self.tgt_vocab.encode_sentence(tgt_sentence, add_eos=True)

        return {
            'src': src_indices,
            'tgt_input': tgt_input_indices,
            'tgt_output': tgt_output_indices,
            'src_text': src_sentence,
            'tgt_text': tgt_sentence
        }

def collate_fn(batch):
    """è‡ªå®šä¹‰çš„æ‰¹å¤„ç†å‡½æ•°ï¼Œç”¨äºå¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—"""

    # è·å–æ‰¹æ¬¡ä¸­æ¯ä¸ªæ ·æœ¬çš„æ•°æ®
    src_sequences = [item['src'] for item in batch]
    tgt_input_sequences = [item['tgt_input'] for item in batch]
    tgt_output_sequences = [item['tgt_output'] for item in batch]

    # å¡«å……åºåˆ—åˆ°ç›¸åŒé•¿åº¦
    src_padded = pad_sequences(src_sequences, en_vocab.word2idx[en_vocab.PAD_TOKEN])
    tgt_input_padded = pad_sequences(tgt_input_sequences, zh_vocab.word2idx[zh_vocab.PAD_TOKEN])
    tgt_output_padded = pad_sequences(tgt_output_sequences, zh_vocab.word2idx[zh_vocab.PAD_TOKEN])

    return {
        'src': torch.tensor(src_padded, dtype=torch.long),
        'tgt_input': torch.tensor(tgt_input_padded, dtype=torch.long),
        'tgt_output': torch.tensor(tgt_output_padded, dtype=torch.long),
        'src_text': [item['src_text'] for item in batch],
        'tgt_text': [item['tgt_text'] for item in batch]
    }

def pad_sequences(sequences, pad_token):
    """å°†åºåˆ—å¡«å……åˆ°ç›¸åŒé•¿åº¦"""
    max_length = max(len(seq) for seq in sequences)
    padded_sequences = []

    for seq in sequences:
        padded_seq = seq + [pad_token] * (max_length - len(seq))
        padded_sequences.append(padded_seq)

    return padded_sequences

# åˆ›å»ºæ•°æ®é›†
dataset = TranslationDataset(raw_data, en_vocab, zh_vocab)

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
batch_size = 4
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)

print(f"ğŸ“¦ æ•°æ®é›†åˆ›å»ºå®Œæˆï¼")
print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(dataset)}")
print(f"ğŸ”„ æ‰¹æ¬¡å¤§å°: {batch_size}")

# æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
sample_batch = next(iter(dataloader))
print(f"\nğŸ” æ ·æœ¬æ‰¹æ¬¡å½¢çŠ¶:")
print(f"   æºåºåˆ—: {sample_batch['src'].shape}")
print(f"   æºåºåˆ—: {sample_batch['src']}")
print(f"   ç›®æ ‡è¾“å…¥: {sample_batch['tgt_input'].shape}")
print(f"   ç›®æ ‡è¾“å…¥: {sample_batch['tgt_input']}")
print(f"   ç›®æ ‡è¾“å‡º: {sample_batch['tgt_output'].shape}")
print(f"   ç›®æ ‡è¾“å‡º: {sample_batch['tgt_output']}")
print(f"     è‹±æ–‡: '{sample_batch['src_text']}'")
print(f"     ä¸­æ–‡: '{sample_batch['tgt_text']}'")

# æ˜¾ç¤ºä¸€ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯
print(f"\nğŸ“ æ ·æœ¬è¯¦æƒ…:")
for i in range(min(2, len(sample_batch['src_text']))):
    print(f"   æ ·æœ¬ {i+1}:")
    print(f"     è‹±æ–‡: '{sample_batch['src_text'][i]}'")
    print(f"     ä¸­æ–‡: '{sample_batch['tgt_text'][i]}'")
    print(f"     è‹±æ–‡ç¼–ç : {sample_batch['src'][i].tolist()}")
    print(f"     ä¸­æ–‡è¾“å…¥ç¼–ç : {sample_batch['tgt_input'][i].tolist()}")
    print(f"     ä¸­æ–‡è¾“å‡ºç¼–ç : {sample_batch['tgt_output'][i].tolist()}")


# 4.2 ç¼–ç å™¨å®ç°ï¼šç†è§£è¾“å…¥åºåˆ—
# è¯æ±‡è¡¨æ„å»ºè¿‡ç¨‹å¯è§†åŒ–å’Œæ•°æ®æµæ¼”ç¤º

print("ğŸ” è¯æ±‡è¡¨æ„å»ºè¿‡ç¨‹è¯¦è§£")
print("=" * 60)

# æ¼”ç¤ºè¯æ±‡è¡¨æ„å»ºè¿‡ç¨‹
print("\nğŸ“š è¯æ±‡è¡¨æ„å»ºæ­¥éª¤æ¼”ç¤º:")
sample_sentences = ["hello world", "good morning", "thank you very much"]

demo_vocab = Vocabulary()
print(f"1. åˆå§‹è¯æ±‡è¡¨ï¼š{list(demo_vocab.idx2word.keys())}")

for i, sentence in enumerate(sample_sentences):
    print(f"\n2.{i+1} æ·»åŠ å¥å­ï¼š'{sentence}'")
    demo_vocab.add_sentence(sentence)
    print(f"     å½“å‰è¯æ±‡è¡¨: {list(demo_vocab.word2idx.keys())}")
    print(f"     è¯æ±‡è¡¨å¤§å°: {len(demo_vocab)}")

print(f"\nğŸ“Š æœ€ç»ˆè¯æ±‡è¡¨ç»Ÿè®¡:")
print(f"   æ€»è¯æ±‡æ•°: {len(demo_vocab)}")
print(f"   ç‰¹æ®Šç¬¦å·æ•°: 4 (PAD, SOS, EOS, UNK)")
print(f"   å®é™…å•è¯æ•°: {len(demo_vocab) - 4}")

# æ¼”ç¤ºç¼–ç å’Œè§£ç è¿‡ç¨‹
print(f"\nğŸ”„ ç¼–ç è§£ç è¿‡ç¨‹æ¼”ç¤º:")
test_sentence = "hello world"
print(f"åŸå§‹å¥å­: '{test_sentence}'")

# ç¼–ç è¿‡ç¨‹
encoded = demo_vocab.encode_sentence(test_sentence)
print(f"ç¼–ç ç»“æœï¼š{encoded}")
print(f"å¯¹åº”è¯æ±‡ï¼š{[demo_vocab.idx2word[idx] for idx in encoded]}")

# è§£ç è¿‡ç¨‹
decoded = demo_vocab.decode_sentence(encoded)
print(f"è§£ç ç»“æœï¼š{decoded}")

# å±•ç¤ºå®é™…æ•°æ®é›†çš„è¯æ±‡åˆ†å¸ƒ
print(f"\nğŸ“ˆ æ•°æ®é›†è¯æ±‡åˆ†å¸ƒåˆ†æ:")
en_words = []
zh_chars = []

for en_sent, zh_sent in raw_data:
    en_words.extend(en_sent.split())
    zh_chars.extend(list(zh_sent))

en_word_freq = Counter(en_words)
zh_char_freq = Counter(zh_chars)

print(f"\nğŸ‡¬ğŸ‡§ è‹±æ–‡è¯æ±‡ç»Ÿè®¡:")
print(f"   æ€»è¯æ±‡æ•°: {len(en_words)} (åŒ…å«é‡å¤)")
print(f"   å”¯ä¸€è¯æ±‡æ•°: {len(en_word_freq)}")
print(f"   æœ€é«˜é¢‘è¯æ±‡: {en_word_freq.most_common(5)}")

print(f"\nğŸ‡¨ğŸ‡³ ä¸­æ–‡å­—ç¬¦ç»Ÿè®¡:")
print(f"   æ€»å­—ç¬¦æ•°: {len(zh_chars)} (åŒ…å«é‡å¤)")
print(f"   å”¯ä¸€å­—ç¬¦æ•°: {len(zh_char_freq)}")
print(f"   æœ€é«˜é¢‘å­—ç¬¦: {zh_char_freq.most_common(5)}")

# æ£€æŸ¥æ•°æ®é›†çš„åºåˆ—é•¿åº¦åˆ†å¸ƒ
en_lengths = [len(sent.split()) for sent, _ in raw_data]
zh_lengths = [len(sent) for _, sent in raw_data]

print(f"\nğŸ“ åºåˆ—é•¿åº¦åˆ†æ:")
print(f"   è‹±æ–‡å¥å­é•¿åº¦: æœ€çŸ­ {min(en_lengths)}, æœ€é•¿ {max(en_lengths)}, å¹³å‡ {sum(en_lengths)/len(en_lengths):.1f} ä¸ªå•è¯")
print(f"   ä¸­æ–‡å¥å­é•¿åº¦: æœ€çŸ­ {min(zh_lengths)}, æœ€é•¿ {max(zh_lengths)}, å¹³å‡ {sum(zh_lengths)/len(zh_lengths):.1f} ä¸ªå­—ç¬¦")

# æ‰¾å‡ºæœ€é•¿å’Œæœ€çŸ­çš„å¥å­
max_en_idx = en_lengths.index(max(en_lengths))
min_en_idx = en_lengths.index(min(en_lengths))

print(f"\nğŸ“ é•¿åº¦ç¤ºä¾‹:")
print(f"   æœ€é•¿è‹±æ–‡å¥å­: '{raw_data[max_en_idx][0]}' (é•¿åº¦: {max(en_lengths)} ä¸ªå•è¯)")
print(f"   æœ€çŸ­è‹±æ–‡å¥å­: '{raw_data[min_en_idx][0]}' (é•¿åº¦: {min(en_lengths)} ä¸ªå•è¯)")

max_zh_idx = zh_lengths.index(max(zh_lengths))
min_zh_idx = zh_lengths.index(min(zh_lengths))

print(f"   æœ€é•¿ä¸­æ–‡å¥å­: '{raw_data[max_zh_idx][1]}' (é•¿åº¦: {max(zh_lengths)} ä¸ªå­—ç¬¦)")
print(f"   æœ€çŸ­ä¸­æ–‡å¥å­: '{raw_data[min_zh_idx][1]}' (é•¿åº¦: {min(zh_lengths)} ä¸ªå­—ç¬¦)")


# ç¼–ç å™¨å®ç°
class Encoder(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=1):
        """
        ç¼–ç å™¨
        Args:
            vocab_size: è¯æ±‡è¡¨å¤§å°
            embedding_dim: è¯åµŒå…¥ç»´åº¦
            hidden_dim: LSTMéšè—å±‚ç»´åº¦
            num_layers: LSTMå±‚æ•°
        """
        super(Encoder, self).__init__()

        self.hidden_dim = hidden_dim
        self.num_layers = num_layers

        # è¯åµŒå…¥å±‚ï¼šå°†è¯ç´¢å¼•è½¬æ¢ä¸ºç¨ å¯†å‘é‡
        self.embedding = nn.Embedding(vocab_size, embedding_dim)

        # LSTMå±‚ï¼šå¤„ç†åºåˆ—ä¿¡æ¯
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers,
                            batch_first=True, bidirectional=False)

    def forward(self, input_seq):
        """
        å‰å‘ä¼ æ’­
        Args:
            input_seq: è¾“å…¥åºåˆ— [batch_size, seq_len]
        Returns:
            outputs: æ‰€æœ‰æ—¶é—´æ­¥çš„è¾“å‡º [batch_size, seq_len, hidden_dim]
            (hidden, cell): æœ€ç»ˆçš„éšçŠ¶æ€å’Œç»†èƒçŠ¶æ€
        """
        # 1. è¯åµŒå…¥ï¼š[batch_size, seq_len] -> [batch_size, seq_len, embedding_dim]
        embedded = self.embedding(input_seq)

        # 2. LSTMå¤„ç†ï¼šè·å–æ‰€æœ‰æ—¶é—´æ­¥çš„è¾“å‡ºå’Œæœ€ç»ˆéšçŠ¶æ€
        outputs, (hidden, cell) = self.lstm(embedded)

        # è¿”å›æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšçŠ¶æ€ä½œä¸ºå¥å­è¡¨ç¤º
        return outputs, (hidden, cell)

# æµ‹è¯•ç¼–ç å™¨
vocab_size = len(en_vocab)
embedding_dim = 64
hidden_dim = 128

encoder = Encoder(vocab_size, embedding_dim, hidden_dim)

print(f"ğŸ—ï¸ ç¼–ç å™¨åˆ›å»ºå®Œæˆï¼")
print(f"ğŸ“ å‚æ•°æ•°é‡: {sum(p.numel() for p in encoder.parameters()):,}")

# æµ‹è¯•ç¼–ç å™¨
test_input = sample_batch['src'][:2]            # å–å‰2ä¸ªæ ·æœ¬æµ‹è¯•
print(f"\nğŸ§ª æµ‹è¯•è¾“å…¥å½¢çŠ¶: {test_input.shape}")

with torch.no_grad():
    outputs, (hidden, cell) = encoder(test_input)
    print(f"âœ… ç¼–ç å™¨è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
    print(f"âœ… æœ€ç»ˆéšçŠ¶æ€å½¢çŠ¶: {hidden.shape}")
    print(f"âœ… æœ€ç»ˆç»†èƒçŠ¶æ€å½¢çŠ¶: {cell.shape}")


# æ•°æ®æµåŠ¨å¯è§†åŒ–ï¼šä»åŸå§‹æ•°æ®åˆ°æ¨¡å‹è¾“å…¥
print("ğŸŒŠ æ•°æ®æµåŠ¨å…¨è¿‡ç¨‹å¯è§†åŒ–")
print("=" * 70)

# é€‰æ‹©ä¸€ä¸ªæ ·æœ¬è¿›è¡Œè¯¦ç»†æ¼”ç¤º
sample_en, sample_zh = raw_data[0]
print(f"ğŸ“ æ¼”ç¤ºæ ·æœ¬: '{sample_en}' â†’ '{sample_zh}'")
print("-" * 50)

# æ­¥éª¤1: åŸå§‹æ•°æ®
print("ğŸ æ­¥éª¤1: åŸå§‹æ•°æ®")
print(f"   è‹±æ–‡: '{sample_en}'")
print(f"   ä¸­æ–‡: '{sample_zh}'")

# æ­¥éª¤2: è¯æ±‡è¡¨ç¼–ç 
print(f"\nğŸ”¤ æ­¥éª¤2: è¯æ±‡è¡¨ç¼–ç ")
en_encoded = en_vocab.encode_sentence(sample_en, add_eos=True)
zh_encoded_input =[zh_vocab.word2idx[zh_vocab.SOS_TOKEN]] + zh_vocab.encode_sentence(sample_zh, add_eos=False)
zh_encoded_target = zh_vocab.encode_sentence(sample_zh, add_eos=True)

print(f"    è‹±æ–‡ç¼–ç ï¼š{en_encoded}")
print(f"      -> å¯¹åº”è¯æ±‡ï¼š{[en_vocab.idx2word[idx] for idx in en_encoded]}")
print(f"    ä¸­æ–‡è¾“å…¥ç¼–ç ï¼š{zh_encoded_input}")
print(f"      -> å¯¹åº”å­—ç¬¦ï¼š{[zh_vocab.idx2word[idx] for idx in zh_encoded_input]}")
print(f"    ä¸­æ–‡ç›®æ ‡ç¼–ç ï¼š{zh_encoded_target}")
print(f"      -> å¯¹åº”å­—ç¬¦ï¼š{[zh_vocab.idx2word[idx] for idx in zh_encoded_target]}")

# æ­¥éª¤3: æ‰¹å¤„ç†å’Œå¡«å……
print(f"\nğŸ“¦ æ­¥éª¤3: æ‰¹å¤„ç†å’Œå¡«å……æ¼”ç¤º")
# æ¨¡æ‹Ÿä¸€ä¸ªå°æ‰¹æ¬¡
mini_batch_indices = [0, 1, 2]
mini_batch_data = [raw_data[i] for i in mini_batch_indices]

print(f"    å°æ‰¹æ¬¡åŸå§‹æ•°æ®ï¼š")
for i, (en, zh) in enumerate(mini_batch_data):
    print(f"    æ ·æœ¬{i}: '{en}' -> â€˜{zh}'")

# ç¼–ç æ‰€æœ‰æ ·æœ¬
batch_en_encoded = []
batch_zh_input_encoded = []
batch_zh_target_encoded = []

for en, zh in mini_batch_data:
    batch_en_encoded.append(en_vocab.encode_sentence(en, add_eos=True))
    batch_zh_input_encoded.append([zh_vocab.word2idx[zh_vocab.SOS_TOKEN]] + zh_vocab.encode_sentence(zh, add_eos=False))
    batch_zh_target_encoded.append(zh_vocab.encode_sentence(zh, add_eos=True))

print(f"\n    ç¼–ç åé•¿åº¦ï¼š")
for i, (en, zh_inp, zh_tgt) in enumerate(zip(batch_en_encoded, batch_zh_input_encoded, batch_zh_target_encoded)):
    print(f"    æ ·æœ¬{i}: en={len(en)}, zh_input={len(zh_inp)}, zh_target={len(zh_tgt)}")

# å¡«å……åˆ°ç›¸åŒé•¿åº¦
batch_en_padded = pad_sequences(batch_en_encoded, en_vocab.word2idx[en_vocab.PAD_TOKEN])
batch_zh_input_padded = pad_sequences(batch_zh_input_encoded, zh_vocab.word2idx[zh_vocab.PAD_TOKEN])
batch_zh_target_padded = pad_sequences(batch_zh_target_encoded, zh_vocab.word2idx[zh_vocab.PAD_TOKEN])

print(f"\n    å¡«å……åï¼š")
for i, (en, zh_inp, zh_tgt) in enumerate(zip(batch_en_padded, batch_zh_input_padded, batch_zh_target_padded)):
    print(f"    æ ·æœ¬{i}: {en}")
    print(f"      -> {[en_vocab.idx2word[idx] for idx in en]}")
    print(f"    æ ·æœ¬{i}: {zh_inp}")
    print(f"      -> {[zh_vocab.idx2word[idx] for idx in zh_inp]}")
    print(f"    æ ·æœ¬{i}: {zh_tgt}")
    print(f"      -> {[zh_vocab.idx2word[idx] for idx in zh_tgt]}")

# æ­¥éª¤4: è½¬æ¢ä¸ºå¼ é‡
print(f"\nğŸ”¢ æ­¥éª¤4: è½¬æ¢ä¸ºPyTorchå¼ é‡")
batch_en_tensor = torch.tensor(batch_en_padded, dtype=torch.long)
batch_zh_input_tensor = torch.tensor(batch_zh_input_padded, dtype=torch.long)
batch_zh_target_tensor = torch.tensor(batch_zh_target_padded, dtype=torch.long)

print(f"   è‹±æ–‡å¼ é‡å½¢çŠ¶: {batch_en_tensor.shape}")
print(f"   ä¸­æ–‡è¾“å…¥å¼ é‡å½¢çŠ¶: {batch_zh_input_tensor.shape}")
print(f"   ä¸­æ–‡ç›®æ ‡å¼ é‡å½¢çŠ¶: {batch_zh_target_tensor.shape}")

print(f"\n  ç¬¬ä¸€ä¸ªæ ·æœ¬çš„å¼ é‡å€¼ï¼š")
print(f"    è‹±æ–‡ï¼š{batch_en_tensor[0]}")
print(f"    ä¸­æ–‡è¾“å…¥ï¼š{batch_zh_input_tensor[0]}")
print(f"    ä¸­æ–‡ç›®æ ‡ï¼š{batch_zh_target_tensor[0]}")

# æ­¥éª¤5: æŸå¤±è®¡ç®—çš„è§£é‡Š
print(f"\nğŸ’¡ æ­¥éª¤5: è®­ç»ƒæ—¶çš„æŸå¤±è®¡ç®—")
print(f"   æ¨¡å‹é¢„æµ‹: åŸºäºè‹±æ–‡å’Œä¸­æ–‡è¾“å…¥ï¼Œé¢„æµ‹ä¸­æ–‡çš„ä¸‹ä¸€ä¸ªå­—ç¬¦")
print(f"   æŸå¤±è®¡ç®—: é¢„æµ‹ç»“æœä¸ä¸­æ–‡ç›®æ ‡æ¯”è¾ƒ")
print(f"   ğŸ’¡ ä¸ºä»€ä¹ˆä¸­æ–‡è¾“å…¥å’Œç›®æ ‡ä¸åŒï¼Ÿ")
print(f"      - è¾“å…¥: [SOS, ä½ ] â†’ æ¨¡å‹çœ‹åˆ°å¼€å§‹æ ‡è®°å’Œå‰é¢çš„å­—ç¬¦")
print(f"      - ç›®æ ‡: [ä½ , EOS] â†’ æ¨¡å‹åº”è¯¥é¢„æµ‹çš„ä¸‹ä¸€ä¸ªå­—ç¬¦")
print(f"      - è¿™æ ·åœ¨æ¯ä¸ªæ—¶é—´æ­¥ï¼Œæ¨¡å‹éƒ½çŸ¥é“åº”è¯¥é¢„æµ‹ä»€ä¹ˆï¼")

print(f"\nğŸ¯ æ•°æ®æµåŠ¨æ€»ç»“:")
print(f"   åŸå§‹æ–‡æœ¬ â†’ åˆ†è¯ â†’ ç¼–ç  â†’ å¡«å…… â†’ å¼ é‡ â†’ æ¨¡å‹ â†’ æŸå¤± â†’ æ¢¯åº¦ â†’ æ›´æ–°")


# 4.3 è§£ç å™¨å®ç°ï¼šç”Ÿæˆè¾“å‡ºåºåˆ—
# è§£ç å™¨å®ç°
class Decoder(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=1):
        """
        è§£ç å™¨
        Args:
            vocab_size: ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨å¤§å°
            embedding_dim: è¯åµŒå…¥ç»´åº¦
            hidden_dim: LSTMéšè—å±‚ç»´åº¦
            num_layers: LSTMå±‚æ•°
        """
        super(Decoder, self).__init__()

        self.vocab_size = vocab_size
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers

        # è¯åµŒå…¥å±‚
        self.embedding = nn.Embedding(vocab_size, embedding_dim)

        # LSTMå±‚ï¼šç”¨äºç”Ÿæˆåºåˆ—
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers,
                            batch_first=True, bidirectional=False)

        # è¾“å‡ºå±‚ï¼šå°†éšçŠ¶æ€æ˜ å°„åˆ°è¯æ±‡è¡¨å¤§å°
        self.output_projection = nn.Linear(hidden_dim, vocab_size)

    def forward(self, input_seq, hidden_state):
        """
        å‰å‘ä¼ æ’­
        Args:
            input_seq: è¾“å…¥åºåˆ— [batch_size, seq_len]
            hidden_state: ç¼–ç å™¨ä¼ æ¥çš„éšçŠ¶æ€ (hidden, cell)
        Returns:
            outputs: è¾“å‡ºåºåˆ—çš„è¯æ±‡åˆ†å¸ƒ [batch_size, seq_len, vocab_size]
            hidden_state: æ›´æ–°åçš„éšçŠ¶æ€
        """
        # 1. è¯åµŒå…¥
        embedded = self.embedding(input_seq)

        # 2. LSTMå¤„ç†
        outputs, hidden_state = self.lstm(embedded, hidden_state)

        # 3. æŠ•å½±åˆ°è¯æ±‡è¡¨
        outputs = self.output_projection(outputs)

        return outputs, hidden_state

    def generate(self, hidden_state, max_length=20, start_token=1, end_token=2):
        """
        ç”Ÿæˆåºåˆ—ï¼ˆæ¨ç†æ—¶ä½¿ç”¨ï¼‰
        Args:
            hidden_state: ç¼–ç å™¨çš„éšçŠ¶æ€
            max_length: ç”Ÿæˆçš„æœ€å¤§é•¿åº¦
            start_token: å¼€å§‹æ ‡è®°çš„ç´¢å¼•
            end_token: ç»“æŸæ ‡è®°çš„ç´¢å¼•
        Returns:
            generated_sequence: ç”Ÿæˆçš„è¯æ±‡ç´¢å¼•åºåˆ—
        """
        batch_size = hidden_state[0].size(1)

        # åˆå§‹åŒ–è¾“å…¥ä¸ºå¼€å§‹æ ‡è®°
        current_input = torch.tensor([[start_token]] * batch_size)

        generated_sequence = []

        for _ in range(max_length):
            # è·å–å½“å‰æ¬¡çš„è¾“å‡º
            output, hidden_state = self.forward(current_input, hidden_state)

            # è´ªå¿ƒé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„è¯
            predicted_word = output.argmax(dim=-1)
            generated_sequence.append(predicted_word.item())

            # å¦‚æœç”Ÿæˆäº†ç»“æŸæ ‡è®°ï¼Œåœæ­¢ç”Ÿæˆ
            if predicted_word.item() == end_token:
                break

            # æ›´æ–°ä¸‹ä¸€æ­¥çš„è¾“å…¥
            current_input = predicted_word

        return generated_sequence

# åˆ›å»ºè§£ç å™¨
zh_vocab_size = len(zh_vocab)
decoder = Decoder(zh_vocab_size, embedding_dim, hidden_dim)

print(f"ğŸ—ï¸ è§£ç å™¨åˆ›å»ºå®Œæˆï¼")
print(f"ğŸ“ å‚æ•°æ•°é‡: {sum(p.numel() for p in decoder.parameters()):,}")

# æµ‹è¯•è§£ç å™¨
test_tgt_input = sample_batch['tgt_input'][:2]
print(f"\nğŸ§ª æµ‹è¯•ç›®æ ‡è¾“å…¥å½¢çŠ¶: {test_tgt_input.shape}")

with torch.no_grad():
    # ä½¿ç”¨ç¼–ç å™¨çš„éšçŠ¶æ€ä½œä¸ºè§£ç å™¨çš„åˆå§‹çŠ¶æ€
    decoder_outputs, _ = decoder(test_tgt_input, (hidden, cell))
    print(f"âœ… è§£ç å™¨è¾“å‡ºå½¢çŠ¶: {decoder_outputs.shape}")
    print(f"âœ… è¾“å‡ºè¯æ±‡åˆ†å¸ƒç»´åº¦: {decoder_outputs.size(-1)} (åº”è¯¥ç­‰äºä¸­æ–‡è¯æ±‡è¡¨å¤§å° {zh_vocab_size})")


# æ¨¡å‹å‚æ•°å’Œè®¡ç®—å¤æ‚åº¦åˆ†æ
print("ğŸ“Š æ¨¡å‹å‚æ•°åˆ†æ")
print("=" * 50)

# æ˜¾ç¤ºç¼–ç å™¨å‚æ•°è¯¦æƒ…
print(f"\nğŸ” ç¼–ç å™¨å‚æ•°è¯¦ç»†åˆ†æ:")
total_params = 0
for name, param in encoder.named_parameters():
    param_count = param.numel()
    total_params += param_count
    print(f"    {name:25s}: {param.shape} -> {param_count:,} å‚æ•°")

print(f"    {'æ€»è®¡':25s}: {total_params:,} å‚æ•°")

# è®¡ç®—å‚æ•°ç»„æˆ
vocab_size = len(en_vocab)
embedding_dim = 64
hidden_dim = 128

print(f"\nğŸ§® å‚æ•°è®¡ç®—éªŒè¯:")
embedding_params = vocab_size * embedding_dim
lstm_params = 4 * (embedding_dim * hidden_dim + hidden_dim * hidden_dim + hidden_dim)           # LSTMå…¬å¼
print(f"  è¯åµŒå…¥å±‚ï¼š{vocab_size} Ã— {embedding_dim} = {embedding_params:,}")
print(f"  LSTMå±‚ï¼š4 Ã— ({embedding_dim} Ã— {hidden_dim} + {hidden_dim} Ã— {hidden_dim} + {hidden_dim} = {lstm_params:,}")
print(f"  æ€»è®¡: {embedding_params + lstm_params:,}")

# å†…å­˜å ç”¨ä¼°è®¡
print(f"\nğŸ’¾ å†…å­˜å ç”¨ä¼°è®¡:")
bytes_per_param = 4         # float32
model_memory_mb = total_params * bytes_per_param / (1024**2)
print(f"  æ¨¡å‹å‚æ•°: {model_memory_mb:.2f} MB")

# è®¡ç®—å¤æ‚åº¦åˆ†æ
print(f"\nâš¡ æ—¶é—´å¤æ‚åº¦åˆ†æ:")
print(f"  ç¼–ç å™¨å‰å‘ä¼ æ’­: O(seq_len Ã— embedding_dim Ã— hidden_dim)")
print(f"  å…¶ä¸­ seq_len â‰ˆ {max([len(sent.split()) for sent, _ in raw_data])}")
print(f"      embedding_dim = {embedding_dim}")
print(f"      hidden_dim = {hidden_dim}")

# å®é™…æµ‹è¯•ç¼–ç å™¨é€Ÿåº¦
import time
test_times = []
test_input = sample_batch['src'][:2]

print(f"\nğŸ•’ å®é™…æ€§èƒ½æµ‹è¯•:")
for i in range(5):
    start_time = time.time()
    with torch.no_grad():
        outputs, (hidden, cell) = encoder(test_input)
    end_time = time.time()
    test_times.append(end_time - start_time)

avg_time = sum(test_times) / len(test_times)
print(f"  ç¼–ç å™¨å‰å‘ä¼ æ’­æ—¶é—´: {avg_time*1000:.2f} ms (å¹³å‡)")
print(f"  å¤„ç†é€Ÿåº¦: {test_input.shape[0]/avg_time:.1f} å¥å­/ç§’")


# 4.4 å®Œæ•´çš„Seq2Seqæ¨¡å‹: å°†ç¼–ç å™¨å’Œè§£ç å™¨ç»„åˆ
# å®Œæ•´çš„Seq2Seqæ¨¡å‹
class Seq2Seq(nn.Module):
    def __init__(self, encoder, decoder, device):
        """
        Seq2Seqæ¨¡å‹
        Args:
            encoder: ç¼–ç å™¨
            decoder: è§£ç å™¨
            device: è®¡ç®—è®¾å¤‡ (cpu/gpu)
        """
        super(Seq2Seq, self).__init__()

        self.encoder = encoder
        self.decoder = decoder
        self.device = device

    def forward(self, src_seq, tgt_seq, teacher_forcing_ratio=1):
        """
        è®­ç»ƒæ—¶çš„å‰å‘ä¼ æ’­
        Args:
            src_seq: æºåºåˆ— [batch_size, src_len]
            tgt_seq: ç›®æ ‡åºåˆ— [batch_size, tgt_len]
            teacher_forcing_ratio: æ•™å¸ˆå¼ºåˆ¶æ¯”ä¾‹
        Returns:
            outputs: è§£ç å™¨è¾“å‡º [batch_size, tgt_len, vocab_size]
        """
        batch_size = src_seq.size(0)
        tgt_len = tgt_seq.size(1)
        vocab_size = self.decoder.vocab_size

        # å­˜å‚¨è§£ç å™¨çš„æ‰€æœ‰è¾“å‡º
        outputs = torch.zeros(batch_size, tgt_len, vocab_size).to(self.device)

        # 1. ç¼–ç é˜¶æ®µ: è·å–æºåºåˆ—çš„è¡¨ç¤º
        _, hidden_state = self.encoder(src_seq)

        # 2. è§£ç é˜¶æ®µ: é€æ­¥ç”Ÿæˆç›®æ ‡åºåˆ—
        # è§£ç å™¨çš„ç¬¬ä¸€ä¸ªè¾“å…¥æ˜¯SOSæ ‡è®°
        decoder_input = tgt_seq[:, :1]          # ç¬¬ä¸€ä¸ªtoken (SOS)

        # ä»ç¬¬0ä¸ªæ—¶é—´æ­¥å¼€å§‹è®­ç»ƒï¼Œè€Œä¸æ˜¯ä»ç¬¬1ä¸ªæ—¶é—´æ­¥
        for t in range(tgt_len):
            # è§£ç å™¨å‰å‘ä¼ æ’­
            output, hidden_state = self.decoder(decoder_input, hidden_state)
            outputs[:, t:t+1, :] = output

            # æ•™å¸ˆå¼ºåˆ¶ï¼šå†³å®šä¸‹ä¸€ä¸ªè¾“å…¥æ˜¯çœŸå®æ ‡ç­¾è¿˜æ˜¯æ¨¡å‹é¢„æµ‹
            use_teacher_forcing = random.random() < teacher_forcing_ratio

            if use_teacher_forcing and t < tgt_len - 1:
                # ä½¿ç”¨çœŸå®çš„ä¸‹ä¸€ä¸ªè¯ä½œä¸ºè¾“å…¥ï¼ˆä½†ä¸è¦è¶…å‡ºåºåˆ—é•¿åº¦ï¼‰
                decoder_input = tgt_seq[:, t+1:t+2]
            else:
                # ä½¿ç”¨æ¨¡å‹é¢„æµ‹çš„è¯ä½œä¸ºè¾“å…¥
                decoder_input = output.argmax(dim=-1)

        return outputs

    def translate(self, src_seq, max_length=20):
        """
        æ¨ç†æ—¶çš„ç¿»è¯‘åŠŸèƒ½
        Args:
            src_seq: æºåºåˆ— [1, src_len]
            max_length: ç”Ÿæˆçš„æœ€å¤§é•¿åº¦
        Returns:
            generated_indices: ç”Ÿæˆçš„è¯æ±‡ç´¢å¼•åˆ—è¡¨
        """
        self.eval()         # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

        with torch.no_grad():
            # ç¼–ç æºåºåˆ—
            _, hidden_state = self.encoder(src_seq)

            # ç”Ÿæˆç›®æ ‡åºåˆ—
            generated_indices = []
            decoder_input = torch.tensor([[zh_vocab.word2idx[zh_vocab.SOS_TOKEN]]]).to(self.device)

            for _ in range(max_length):
                output, hidden_state = self.decoder(decoder_input, hidden_state)
                predicted_id = output.argmax(dim=-1).item()

                generated_indices.append(predicted_id)

                # å¦‚æœé¢„æµ‹åˆ°ç»“æŸæ ‡è®°ï¼Œåœæ­¢ç”Ÿæˆ
                if predicted_id == zh_vocab.word2idx[zh_vocab.EOS_TOKEN]:
                    break

                # ä¸‹ä¸€æ­¥çš„è¾“å…¥æ˜¯å½“å‰é¢„æµ‹çš„è¯
                decoder_input = torch.tensor([[predicted_id]]).to(self.device)

        return generated_indices

# åˆ›å»ºè®¾å¤‡å¯¹è±¡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åˆ›å»ºå®Œæ•´çš„Seq2Seqæ¨¡å‹
model = Seq2Seq(encoder, decoder, device).to(device)

print(f"ğŸ¯ Seq2Seqæ¨¡å‹åˆ›å»ºå®Œæˆï¼")
print(f"ğŸ“± è¿è¡Œè®¾å¤‡: {device}")
print(f"ğŸ“ æ€»å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

# æ˜¾ç¤ºæ¨¡å‹ç»“æ„
print(f"\nğŸ—ï¸ æ¨¡å‹ç»“æ„:")
print(f"  ç¼–ç å™¨å‚æ•°: {sum(p.numel() for p in model.encoder.parameters()):,}")
print(f"  è§£ç å™¨å‚æ•°: {sum(p.numel() for p in model.decoder.parameters()):,}")

# æµ‹è¯•æ¨¡å‹
test_src = sample_batch['src'][:1].to(device)               # å–ä¸€ä¸ªæ ·æœ¬
test_tgt = sample_batch['tgt_input'][:1].to(device)

print(f"\nğŸ§ª æ¨¡å‹æµ‹è¯•:")
print(f"  è¾“å…¥å½¢çŠ¶: {test_src.shape}")
print(f"  ç›®æ ‡å½¢çŠ¶: {test_tgt.shape}")

with torch.no_grad():
    outputs = model(test_src, test_tgt, teacher_forcing_ratio=1.0)
    print(f"âœ… æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {outputs.shape}")


# è®­ç»ƒæˆ‘ä»¬çš„ç¿»è¯‘æ¨¡å‹
# è®­ç»ƒ vs æ¨ç†è¯¦ç»†å¯¹æ¯”æ¼”ç¤º
print("ğŸ­ è®­ç»ƒæ¨¡å¼ vs æ¨ç†æ¨¡å¼è¯¦ç»†å¯¹æ¯”")
print("=" * 70)

# ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥æ¼”ç¤º
demo_en = "hello"
demo_zh = "ä½ å¥½"

print(f"ğŸ“ æ¼”ç¤ºå¥å­: '{demo_en}' â†’ '{demo_zh}'")
print("-" * 50)

# å‡†å¤‡è¾“å…¥æ•°æ®
src_tensor = torch.tensor([en_vocab.encode_sentence(demo_en)]).to(device)
tgt_input = [zh_vocab.word2idx[zh_vocab.SOS_TOKEN]] + zh_vocab.encode_sentence(demo_zh, add_eos=False)
tgt_input_tensor = torch.tensor([tgt_input]).to(device)
tgt_output = zh_vocab.encode_sentence(demo_zh, add_eos=True)

print(f"ğŸ“ è®­ç»ƒæ¨¡å¼æ¼”ç¤º:")
print(f"  è¾“å…¥ç¼–ç : {src_tensor.tolist()[0]} -> {[en_vocab.idx2word[i] for i in src_tensor.tolist()[0]]}")
print(f"  ç›®æ ‡è¾“å…¥: {tgt_input_tensor.tolist()[0]} -> {[zh_vocab.idx2word[i] for i in tgt_input_tensor.tolist()[0]]}")
print(f"  ç›®æ ‡è¾“å‡º: {tgt_output} -> {[zh_vocab.idx2word[i] for i in tgt_output]}")

# è®­ç»ƒæ¨¡å¼çš„è¯¦ç»†æ­¥éª¤
model.train()
print(f"\n  ğŸ”„ è®­ç»ƒæ­¥éª¤è¯¦è§£:")

# ç¼–ç é˜¶æ®µ
with torch.no_grad():
    _, (encoder_hidden, encoder_cell) = model.encoder(src_tensor)
    print(f"  1. ç¼–ç å™¨å¤„ç†: '{demo_en}' -> éšçŠ¶æ€å½¢çŠ¶ {encoder_hidden.shape}")

    # è§£ç é˜¶æ®µï¼ˆæ¨¡æ‹Ÿï¼‰
    decoder_hidden = encoder_hidden
    decoder_cell = encoder_cell

    print(f"  2. è§£ç å™¨æ­¥éª¤:")
    for t in range(len(tgt_input)):
        current_input = tgt_input_tensor[:, t:t+1]          # å½“å‰æ—¶é—´æ­¥è¾“å…¥

        # è§£ç å™¨å‰å‘ä¼ æ’­
        decoder_output, (decoder_hidden, decoder_cell) = model.decoder(current_input, (decoder_hidden, decoder_cell))
        predicted_id = decoder_output.argmax(dim=-1).item()
        predicted_word = zh_vocab.idx2word[predicted_id]

        if t < len(tgt_input):
            true_word = zh_vocab.idx2word[tgt_output[t]]
            print(f"    æ­¥éª¤{t+1}: è¾“å…¥'{zh_vocab.idx2word[current_input.item()]}' -> é¢„æµ‹'{predicted_word}' (çœŸå®: '{true_word}')")
        else:
            print(f"    æ­¥éª¤{t+1}: è¾“å…¥'{zh_vocab.idx2word[current_input.item()]}' -> é¢„æµ‹'{predicted_word}'")

print(f"\nğŸ”® æ¨ç†æ¨¡å¼æ¼”ç¤º:")
model.eval()

# æ¨ç†æ¨¡å¼çš„è¯¦ç»†æ­¥éª¤
print(f"    è¾“å…¥ç¼–ç : {src_tensor.tolist()[0]} -> {[en_vocab.idx2word[i] for i in src_tensor.tolist()[0]]}")
print(f"    ç›®æ ‡è¾“å‡º: æœªçŸ¥ï¼éœ€è¦é€æ­¥ç”Ÿæˆ")

print(f"\n   ğŸ”„ æ¨ç†æ­¥éª¤è¯¦è§£:")
with torch.no_grad():
    # ç¼–ç é˜¶æ®µ
    _, (encoder_hidden, encoder_cell) = model.encoder(src_tensor)
    print(f"    1. ç¼–ç å™¨å¤„ç†: '{demo_en}' -> éšçŠ¶æ€å½¢çŠ¶ {encoder_hidden.shape}")

    # è§£ç é˜¶æ®µ
    decoder_hidden = encoder_hidden
    decoder_cell = encoder_cell

    current_input = torch.tensor([[zh_vocab.word2idx[zh_vocab.SOS_TOKEN]]]).to(device)
    generated_sequence = []

    print(f"    2. è§£ç å™¨æ­¥éª¤:")
    for t in range(5):              # æœ€å¤šç”Ÿæˆ5ä¸ªè¯
        # è§£ç å™¨å‰å‘ä¼ æ’­
        decoder_output, (decoder_hidden, decoder_cell) = model.decoder(current_input, (decoder_hidden, decoder_cell))
        predicted_id = decoder_output.argmax(dim=-1).item()
        predicted_word = zh_vocab.idx2word[predicted_id]

        print(f"    æ­¥éª¤{t+1}: è¾“å…¥'{zh_vocab.idx2word[current_input.item()]}' -> é¢„æµ‹'{predicted_word}'")

        generated_sequence.append(predicted_id)

        # åœæ­¢æ¡ä»¶
        if predicted_id == zh_vocab.word2idx[zh_vocab.EOS_TOKEN]:
            print(f"        é‡åˆ°ç»“æŸç¬¦ï¼Œåœæ­¢ç”Ÿæˆ")
            break

        # ä¸‹ä¸€æ­¥çš„è¾“å…¥æ˜¯å½“å‰çš„é¢„æµ‹ï¼ˆå…³é”®åŒºåˆ«ï¼ï¼‰
        current_input = torch.tensor([[predicted_id]]).to(device)

    generated_text = zh_vocab.decode_sentence(generated_sequence)
    print(f"    3. æœ€ç»ˆç”Ÿæˆ: '{generated_text}'")

print(f"\nğŸ’¡ å…³é”®åŒºåˆ«æ€»ç»“:")
print(f"   ğŸ“ è®­ç»ƒæ¨¡å¼:")
print(f"      - è§£ç å™¨è¾“å…¥: ä½¿ç”¨çœŸå®çš„ç›®æ ‡åºåˆ— (Teacher Forcing)")
print(f"      - ä¼˜ç‚¹: è®­ç»ƒç¨³å®šã€å¿«é€Ÿ")
print(f"      - ç¼ºç‚¹: ä¸æ¨ç†ä¸ä¸€è‡´")
print(f"   ğŸ”® æ¨ç†æ¨¡å¼:")
print(f"      - è§£ç å™¨è¾“å…¥: ä½¿ç”¨è‡ªå·±çš„é¢„æµ‹ç»“æœ")
print(f"      - ä¼˜ç‚¹: çœŸå®çš„ä½¿ç”¨åœºæ™¯")
print(f"      - ç¼ºç‚¹: é”™è¯¯ä¼šç´¯ç§¯ä¼ æ’­")

print(f"\nâš ï¸  æ›å…‰åå·® (Exposure Bias):")
print(f"   é—®é¢˜: è®­ç»ƒæ—¶æ¨¡å‹ä»æœªè§è¿‡è‡ªå·±çš„é”™è¯¯é¢„æµ‹")
print(f"   åæœ: æ¨ç†æ—¶ä¸€æ—¦å‡ºé”™ï¼Œå¯èƒ½ä¸€é”™åˆ°åº•")
print(f"   è§£å†³æ–¹æ¡ˆ: è°ƒåº¦é‡‡æ ·ã€å¼ºåŒ–å­¦ä¹ ç­‰é«˜çº§æŠ€æœ¯")


# è®­ç»ƒå’Œè¯„ä¼°å‡½æ•°
def train_epoch(model, dataloader, optimizer, criterion, device):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0

    for batch_idx, batch in enumerate(dataloader):
        # å°†æ•°æ®ç§»åˆ°è®¾å¤‡ä¸Š
        src = batch['src'].to(device)
        tgt_input = batch['tgt_input'].to(device)
        tgt_output = batch['tgt_output'].to(device)

        # æ¸…é›¶æ¢¯åº¦
        optimizer.zero_grad()

        # å‰å‘ä¼ æ’­
        output = model(src, tgt_input, teacher_forcing_ratio=0.5)

        # è®¡ç®—æŸå¤±ï¼ˆå¿½ç•¥å¡«å……ç¬¦å·ï¼‰
        # ä¸å†å»æ‰ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œå› ä¸ºç°åœ¨æ¨¡å‹ä¼šå­¦ä¹ é¢„æµ‹ç¬¬ä¸€ä¸ªå­—ç¬¦
        output = output.reshape(-1, output.size(-1))                # å±•å¹³æ‰€æœ‰æ—¶é—´æ­¥
        tgt_output = tgt_output.reshape(-1)                         # å±•å¹³æ‰€æœ‰æ—¶é—´æ­¥

        loss = criterion(output, tgt_output)

        # åå‘ä¼ æ’­
        loss.backward()

        # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

        # æ›´æ–°å‚æ•°
        optimizer.step()

        total_loss += loss.item()

        if batch_idx % 5 == 0:              # æ¯5ä¸ªbatchæ‰“å°ä¸€æ¬¡
            print(f'  Batch {batch_idx + 1}/{len(dataloader)}, Loss: {loss.item():.4f}')

    return total_loss / len(dataloader)

def evaluate_model(model, dataloader, criterion, device):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    total_loss = 0

    with torch.no_grad():
        for batch in dataloader:
            src = batch['src'].to(device)
            tgt_input = batch['tgt_input'].to(device)
            tgt_output = batch['tgt_output'].to(device)

            # å‰å‘ä¼ æ’­ï¼ˆä¸ä½¿ç”¨æ•™å¸ˆå¼ºåˆ¶ï¼‰
            output = model(src, tgt_input, teacher_forcing_ratio=0)

            # è®¡ç®—æŸå¤±ï¼Œä¸å†å»æ‰ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥
            output = output.reshape(-1, output.size(-1))
            tgt_output = tgt_output.reshape(-1)

            loss = criterion(output, tgt_output)
            total_loss += loss.item()

    return total_loss / len(dataloader)

def translate_sentence(model, sentence, src_vocab, tgt_vocab, device, max_length=20):
    """ç¿»è¯‘å•ä¸ªå¥å­"""
    model.eval()

    # é¢„å¤„ç†å¥å­
    tokens = sentence.lower().split()
    indices = [src_vocab.word2idx.get(token, src_vocab.word2idx[src_vocab.UNK_TOKEN]) for token in tokens]
    indices.append(src_vocab.word2idx[src_vocab.EOS_TOKEN])

    # è½¬æ¢ä¸ºtensor
    src_tensor = torch.tensor([indices]).to(device)

    # ç¿»è¯‘
    with torch.no_grad():
        generated_indices = model.translate(src_tensor, max_length)

    # è§£ç ä¸ºæ–‡æœ¬
    translation = tgt_vocab.decode_sentence(generated_indices)

    return translation

# è®¾ç½®è®­ç»ƒå‚æ•°
criterion = nn.CrossEntropyLoss(ignore_index=zh_vocab.word2idx[zh_vocab.PAD_TOKEN])
optimizer = optim.Adam(model.parameters(), lr=0.001)

print("ğŸ‹ï¸ è®­ç»ƒè®¾ç½®å®Œæˆï¼")
print(f"ğŸ“‰ æŸå¤±å‡½æ•°: CrossEntropyLoss (å¿½ç•¥å¡«å……ç¬¦å·)")
print(f"ğŸ”§ ä¼˜åŒ–å™¨: Adam (å­¦ä¹ ç‡: 0.001)")
print(f"ğŸ¯ è®¾å¤‡: {device}")


# éªŒè¯ä¿®å¤æ•ˆæœ
print("ğŸ”§ éªŒè¯ä¿®å¤æ•ˆæœ")
print("=" * 50)

# é‡æ–°åˆ›å»ºæ¨¡å‹ä»¥åº”ç”¨ä¿®å¤
model = Seq2Seq(encoder, decoder, device).to(device)

# ç®€å•æµ‹è¯•è®­ç»ƒæ˜¯å¦æ­£å¸¸
print("\nğŸ§ª æµ‹è¯•ä¿®å¤åçš„è®­ç»ƒæµç¨‹:")
test_batch = next(iter(dataloader))
src = test_batch['src'][:2].to(device)
tgt_input = test_batch['tgt_input'][:2].to(device)
tgt_output = test_batch['tgt_output'][:2].to(device)

print(f"   æºåºåˆ—å½¢çŠ¶: {src.shape}")
print(f"   ç›®æ ‡è¾“å…¥å½¢çŠ¶: {tgt_input.shape}")
print(f"   ç›®æ ‡è¾“å‡ºå½¢çŠ¶: {tgt_output.shape}")

# æµ‹è¯•å‰å‘ä¼ æ’­
model.train()
with torch.no_grad():
    output = model(src, tgt_input, teacher_forcing_ratio=1.0)
    print(f"    æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}")

    # æµ‹è¯•æŸå¤±è®¡ç®—
    criterion = nn.CrossEntropyLoss(ignore_index=zh_vocab.word2idx[zh_vocab.PAD_TOKEN])
    output_flat = output.reshape(-1, output.size(-1))
    tgt_output_flat = tgt_output.reshape(-1)
    loss = criterion(output_flat, tgt_output_flat)
    print(f"    æŸå¤±è®¡ç®—æˆåŠŸï¼ŒæŸå¤±å€¼: {loss.item():.4f}")

# æµ‹è¯•æ¨ç†
print(f"\nğŸ”® æµ‹è¯•ä¿®å¤åçš„æ¨ç†:")
test_sentences = ["hi.", "hello!", "good morning"]
for sentence in test_sentences:
    translation = translate_sentence(model, sentence, en_vocab, zh_vocab, device)
    print(f"    '{sentence}' -> '{translation}'")

print(f"\nâœ… ä¿®å¤éªŒè¯å®Œæˆï¼")
print(f"æ³¨æ„ï¼šç”±äºæ¨¡å‹å°šæœªé‡æ–°è®­ç»ƒï¼Œé¢„æµ‹ç»“æœå¯èƒ½ä»ç„¶ä¸å‡†ç¡®ã€‚")
print(f"ä½†ç°åœ¨æ¨¡å‹çš„æ¶æ„å·²ç»ä¿®å¤ï¼Œé‡æ–°è®­ç»ƒååº”è¯¥èƒ½æ­£ç¡®é¢„æµ‹ç¬¬ä¸€ä¸ªå­—ç¬¦ã€‚")

# å¼€å§‹è®­ç»ƒ
print("ğŸš€ å¼€å§‹è®­ç»ƒSeq2Seqæ¨¡å‹...")
print("=" * 50)

num_epochs = 50         # ç”±äºæ•°æ®é›†å¾ˆå°ï¼Œæˆ‘ä»¬å¤šè®­ç»ƒå‡ è½®
train_losses = []
best_loss = float('inf')

for epoch in range(num_epochs):
    print(f"\nğŸ“š Epoch {epoch + 1}/{num_epochs}")

    # è®­ç»ƒ
    train_loss = train_epoch(model, dataloader, optimizer, criterion, device)
    train_losses.append(train_loss)

    print(f"âœ… å¹³å‡è®­ç»ƒæŸå¤±: {train_loss:.4f}")

    # æ¯10ä¸ªepochæµ‹è¯•ç¿»è¯‘æ•ˆæœ
    if (epoch + 1) % 10 == 0:
        print("\nğŸ” ç¿»è¯‘æµ‹è¯•:")
        test_sentences = ["hello", "thank you", "i love you", "good morning"]

        for sentence in test_sentences:
            translation = translate_sentence(model, sentence, en_vocab, zh_vocab, device)
            print(f"    '{sentence}' -> '{translation}'")

    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if train_loss < best_loss:
        best_loss = train_loss
        torch.save(model.state_dict(), "best_seq2seq_model.pt")

print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³æŸå¤±: {best_loss:.4f}")
print("æ¨¡å‹å·²ä¿å­˜ä¸º 'best_seq2seq_model.pth'")
