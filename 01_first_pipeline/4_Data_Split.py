# æ•°æ®åˆ†å‰²å®æˆ˜ä»£ç 
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# è®¾ç½®å­—ä½“ï¼ˆä½¿ç”¨è‹±æ–‡é¿å…ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun']
plt.rcParams['axes.unicode_minus'] = False

# ä½¿ç”¨å‰é¢æ¸…ç†å¥½çš„æ•°æ®ï¼Œè¿™é‡Œåˆ›å»ºä¸€ä¸ªæ›´å¤§çš„æ¨¡æ‹Ÿæ•°æ®é›†
np.random.seed(42)

# æ¨¡æ‹Ÿæ™ºèƒ½å®¢æœæ•°æ®é›†
intents = ['é€€æ¬¾å’¨è¯¢', 'ç‰©æµæŸ¥è¯¢', 'ä¼˜æƒ å’¨è¯¢', 'å”®åæŠ•è¯‰', 'è”ç³»æ–¹å¼',
           'æ¢è´§å’¨è¯¢', 'ä½¿ç”¨å’¨è¯¢', 'äº§å“å’¨è¯¢', 'è®¢å•æŸ¥è¯¢', 'æŠ€æœ¯æ”¯æŒ']

# æ¨¡æ‹Ÿä¸å¹³è¡¡çš„æ•°æ®åˆ†å¸ƒï¼ˆç¬¦åˆå®é™…æƒ…å†µï¼‰
intent_weights = [0.25, 0.20, 0.15, 0.12, 0.08, 0.06, 0.05, 0.04, 0.03, 0.02]

# ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
data_size = 1000
texts = []
labels = []

for i in range(data_size):
    intent = np.random.choice(intents, p=intent_weights)
    # ç®€å•æ¨¡æ‹Ÿæ–‡æœ¬
    text = f"è¿™æ˜¯ä¸€æ¡å…³äº{intent}çš„ç”¨æˆ·é—®è¯¢{i}"
    texts.append(text)
    labels.append(intent)

df = pd.DataFrame({
    'text': texts,
    'intent': labels}
)

print("ğŸ“Š === åŸå§‹æ•°æ®æ¦‚è§ˆ ===")
print(f"æ€»æ•°æ®é‡: {len(df)} æ¡")
print("\nå„æ„å›¾åˆ†å¸ƒ:")
intent_counts = df['intent'].value_counts()
for intent, count in intent_counts.items():
    percentage = count / len(df) * 100
    print(f"  {intent}: {count:3d}æ¡ ({percentage:.2f}%)")

# å¯è§†åŒ–åŸå§‹æ•°æ®åˆ†å¸ƒ
plt.figure(figsize=(16, 6))

plt.subplot(1, 2, 1)
intent_counts.plot(kind='bar', color='skyblue', alpha=0.7)
plt.title('åŸå§‹æ•°æ®åˆ†å¸ƒ', fontsize=12, weight='bold')
plt.xlabel('æ„å›¾ç±»åˆ«')
plt.ylabel('æ•°é‡')
plt.xticks(rotation=45)

print("\nâœ‚ï¸ === æ–¹æ³•1: ç®€å•éšæœºåˆ†å‰² ===")

# æ–¹æ³•1ï¼šç®€å•éšæœºåˆ†å‰²
x = df['text']
y = df['intent']

x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)
x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

print(f"è®­ç»ƒé›†: {len(x_train)} æ¡ ({len(x_train)/len(df)*100:.1f}%)")
print(f"éªŒè¯é›†: {len(x_val)} æ¡ ({len(x_val)/len(df)*100:.1f}%)")
print(f"æµ‹è¯•é›†: {len(x_test)} æ¡ ({len(x_test)/len(df)*100:.1f}%)")

# æ£€æŸ¥éšæœºåˆ†å‰²åçš„ç±»åˆ«åˆ†å¸ƒ
print("\nå„é›†åˆä¸­çš„ç±»åˆ«åˆ†å¸ƒï¼š")
for dataset_name, y_data in [('è®­ç»ƒé›†', y_train), ('éªŒè¯é›†', y_val), ('æµ‹è¯•é›†', y_test)]:
    print(f"\n{dataset_name}:")
    dist = y_data.value_counts(normalize=True).sort_index()
    for intent in intents[:]:
        if intent in dist:
            print(f"  {intent}: {dist[intent] * 100:.2f}%")

# æ–¹æ³•2ï¼šåˆ†å±‚åˆ†å‰²ï¼Œä¿è¯å„ç±»åˆ«æ¯”ä¾‹ä¸€è‡´
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)
train_idx, temp_idx = next(sss.split(x, y))

x_train_strat = x.iloc[train_idx]
y_train_strat = y.iloc[train_idx]
x_temp_strat = x.iloc[temp_idx]
y_temp_strat = y.iloc[temp_idx]

# å†æ¬¡åˆ†å‰²éªŒè¯é›†å’Œæµ‹è¯•é›†
sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)
val_idx, test_idx = next(sss2.split(x_temp_strat, y_temp_strat))

x_val_strat = x_temp_strat.iloc[val_idx]
y_val_strat = y_temp_strat.iloc[val_idx]
x_test_strat = x_temp_strat.iloc[test_idx]
y_test_strat = y_temp_strat.iloc[test_idx]

print(f"è®­ç»ƒé›†: {len(x_train_strat)} æ¡ ({len(x_train_strat)/len(df)*100:.1f}%)")
print(f"éªŒè¯é›†: {len(x_val_strat)} æ¡ ({len(x_val_strat)/len(df)*100:.1f}%)")
print(f"æµ‹è¯•é›†: {len(x_test_strat)} æ¡ ({len(x_test_strat)/len(df)*100:.1f}%)")

print("\nåˆ†å±‚åˆ†å‰²åçš„ç±»åˆ«åˆ†å¸ƒï¼š")
for dataset_name, y_data in [('è®­ç»ƒé›†', y_train_strat), ('éªŒè¯é›†', y_val_strat), ('æµ‹è¯•é›†', y_test_strat)]:
    print(f"\n{dataset_name}:")
    dist = y_data.value_counts(normalize=True).sort_index()
    for intent in intents[:]:
        if intent in dist:
            print(f"  {intent}: {dist[intent] * 100:.2f}%")

# å¯è§†åŒ–åˆ†å‰²ç»“æœæ¯”è¾ƒ
plt.subplot(1, 2, 2)
comparison_data = {
    'åŸå§‹': intent_counts,
    'è®­ç»ƒé›†': y_train_strat.value_counts(),
    'æµ‹è¯•é›†': y_test_strat.value_counts(),
}

x = np.arange(len(intent_counts))  # ä½¿ç”¨æ‰€æœ‰ç±»åˆ«çš„æ•°é‡
width = 0.25

for i, (name, data) in enumerate(comparison_data.items()):
    # ç¡®ä¿æ‰€æœ‰æ•°æ®é›†éƒ½åŒ…å«ç›¸åŒçš„ç±»åˆ«é¡ºåº
    data_aligned = data.reindex(intent_counts.index, fill_value=0)
    plt.bar(x + i * width, data_aligned.values, width, label=name, alpha=0.8)

plt.title('åˆ†å±‚åˆ†å‰²æ•ˆæœå¯¹æ¯”', fontsize=12, weight='bold')
plt.xlabel('æ„å›¾ç±»åˆ«')
plt.ylabel('æ•°é‡')
plt.xticks(x + width, intent_counts.index, rotation=45)
plt.legend()

plt.tight_layout()
plt.show()

print("\nğŸ¯ === åˆ†å‰²è´¨é‡éªŒè¯ ===")

# è®¡ç®—åˆ†å¸ƒå·®å¼‚
def calculate_distribution_difference(original, subset):
    """è®¡ç®—åˆ†å¸ƒå·®å¼‚"""
    orig_dist = original.value_counts(normalize=True).sort_index()
    subset_dist = subset.value_counts(normalize=True).sort_index()

    # ç¡®ä¿æ‰€æœ‰ç±»åˆ«éƒ½å­˜åœ¨
    all_classes = orig_dist.index.union(subset_dist.index)
    orig_dist = orig_dist.reindex(all_classes, fill_value=0)
    subset_dist = subset_dist.reindex(all_classes, fill_value=0)

    # è®¡ç®—å¹³å‡ç»å¯¹å·®å¼‚
    diff = np.mean(np.abs(orig_dist - subset_dist))
    return diff

print("ä¸åŸå§‹åˆ†å¸ƒçš„å·®å¼‚åº¦ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ï¼š")
print(f"éšæœºåˆ†å‰² - è®­ç»ƒé›†ï¼š{calculate_distribution_difference(y, y_train):.4f}")
print(f"éšæœºåˆ†å‰² - æµ‹è¯•é›†ï¼š{calculate_distribution_difference(y, y_test):.4f}")
print(f"åˆ†å±‚åˆ†å‰² - è®­ç»ƒé›†ï¼š{calculate_distribution_difference(y, y_train_strat):.4f}")
print(f"åˆ†å±‚åˆ†å‰² - æµ‹è¯•é›†ï¼š{calculate_distribution_difference(y, y_test_strat):.4f}")

print("\nâœ… === æ•°æ®åˆ†å‰²æ€»ç»“ ===")
print("ğŸ¯ æ¨èæ–¹æ¡ˆ: åˆ†å±‚åˆ†å‰²")
print("ğŸ“Š åˆ†å‰²æ¯”ä¾‹: 70% è®­ç»ƒ + 15% éªŒè¯ + 15% æµ‹è¯•")
print("âœ… ä¼˜åŠ¿: ä¿è¯äº†å„ç±»åˆ«åœ¨ä¸åŒé›†åˆä¸­çš„åˆ†å¸ƒä¸€è‡´æ€§")
print("âœ… ç»“æœ: æ¨¡å‹è®­ç»ƒæ›´ç¨³å®šï¼Œè¯„ä¼°æ›´å¯é ")

print("\nğŸ’¾ === ä¿å­˜åˆ†å‰²åçš„æ•°æ® ===")
print("âœ… è®­ç»ƒé›†å·²å‡†å¤‡å¥½ç”¨äºæ¨¡å‹è®­ç»ƒ")
print("âœ… éªŒè¯é›†å·²å‡†å¤‡å¥½ç”¨äºè¶…å‚æ•°è°ƒä¼˜")
print("âœ… æµ‹è¯•é›†å·²å‡†å¤‡å¥½ç”¨äºæœ€ç»ˆè¯„ä¼°")
print("âœ… å¯ä»¥å¼€å§‹ä¸‹ä¸€æ­¥ï¼šç‰¹å¾å·¥ç¨‹ï¼")
