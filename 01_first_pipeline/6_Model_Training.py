# å»ºæ¨¡å®æˆ˜ä»£ç 
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
import jieba
import time

# å‡†å¤‡æ›´å¤§çš„æ¨¡æ‹Ÿæ•°æ®é›†ç”¨äºå»ºæ¨¡
np.random.seed(42)

# ç”Ÿæˆæ¨¡æ‹Ÿçš„æ™ºèƒ½å®¢æœæ•°æ®
def generate_sample_data(n_samples=500):
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„æ™ºèƒ½å®¢æœæ•°æ®"""
    intents = ['é€€æ¬¾å’¨è¯¢', 'ç‰©æµæŸ¥è¯¢', 'ä¼˜æƒ å’¨è¯¢', 'å”®åæŠ•è¯‰', 'è”ç³»æ–¹å¼']

    # ä¸åŒæ„å›¾çš„æ¨¡æ¿
    templates = {
        'é€€æ¬¾å’¨è¯¢': ['æ€ä¹ˆé€€æ¬¾', 'é€€æ¬¾æµç¨‹', 'ç”³è¯·é€€æ¬¾', 'é’±ä»€ä¹ˆæ—¶å€™é€€å›æ¥', 'é€€æ¬¾è¦å¤šä¹…'],
        'ç‰©æµæŸ¥è¯¢': ['ä»€ä¹ˆæ—¶å€™å‘è´§', 'æŸ¥è¯¢ç‰©æµ', 'å¿«é€’åˆ°å“ªäº†', 'å¤šä¹…èƒ½æ”¶åˆ°è´§', 'ç‰©æµä¿¡æ¯'],
        'ä¼˜æƒ å’¨è¯¢': ['æœ‰ä»€ä¹ˆä¼˜æƒ ', 'æ‰“æŠ˜æ´»åŠ¨', 'ä¼˜æƒ åˆ¸æ€ä¹ˆç”¨', 'ä¿ƒé”€ä¿¡æ¯', 'ä¼šå‘˜ä»·æ ¼'],
        'å”®åæŠ•è¯‰': ['äº§å“æœ‰é—®é¢˜', 'è´¨é‡ä¸å¥½', 'è¦æŠ•è¯‰', 'æœåŠ¡æ€åº¦å·®', 'ä¸æ»¡æ„'],
        'è”ç³»æ–¹å¼': ['å®¢æœç”µè¯', 'è”ç³»æ–¹å¼', 'äººå·¥å®¢æœ', 'åœ¨çº¿å®¢æœ', 'å®¢æœQQ']
    }

    sample_texts = []
    sample_labels = []

    for _ in range(n_samples):
        intent = np.random.choice(intents)
        template = np.random.choice(templates[intent])

        # æ·»åŠ ä¸€äº›éšæœºå˜åŒ–
        variations = ['ï¼Ÿ', 'ï¼', 'å‘¢', 'å—', 'å•Š', 'ï¼Œæ€¥æ€¥æ€¥', 'ï¼Œè°¢è°¢']
        text = template + np.random.choice(variations)

        sample_texts.append(text)
        sample_labels.append(intent)

    return sample_texts, sample_labels

# ç”Ÿæˆè®­ç»ƒæ•°æ®
texts, labels = generate_sample_data(500)
df = pd.DataFrame({'text': texts, 'intent': labels})

print("ğŸ¤– === å»ºæ¨¡æ•°æ®å‡†å¤‡ ===")
print(f"æ•°æ®é‡: {len(df)} æ¡")
print("æ„å›¾åˆ†å¸ƒ:")
print(df['intent'].value_counts())

# æ–‡æœ¬é¢„å¤„ç†
def preprocess_text(text):
    """ç®€å•çš„æ–‡æœ¬é¢„å¤„ç†"""
    words = jieba.lcut(text)
    # å»é™¤åœç”¨è¯
    stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´',
                  'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è¿™'}
    words = [w for w in words if w not in stop_words and len(w.strip()) > 1]
    return ' '.join(words)

# é¢„å¤„ç†æ–‡æœ¬
processed_texts = [preprocess_text(text) for text in df['text']]

# ç‰¹å¾æå–
tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))
x = tfidf.fit_transform(processed_texts)
y = df['intent']

# æ•°æ®åˆ†å‰²
x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nè®­ç»ƒé›†: {x_train.shape[0]} æ¡")
print(f"æµ‹è¯•é›†: {x_test.shape[0]} æ¡")
print(f"ç‰¹å¾ç»´åº¦: {x_train.shape[1]} ç»´")

print("\nğŸ§  === æ¨¡å‹è®­ç»ƒå¯¹æ¯” ===")

# å®šä¹‰å¤šä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”
models = {
    'æœ´ç´ è´å¶æ–¯': MultinomialNB(),
    'é€»è¾‘å›å½’': LogisticRegression(random_state=42, max_iter=1000),
    'éšæœºæ£®æ—': RandomForestClassifier(n_estimators=100, random_state=42),
    'æ”¯æŒå‘é‡æœº': SVC(kernel='linear', random_state=42),
    'Kè¿‘é‚»': KNeighborsClassifier(n_neighbors=5)
}

# å­˜å‚¨ç»“æœ
results = {}
traning_times = {}

print("å¼€å§‹è®­ç»ƒå„ç§æ¨¡å‹...")
for name, model in models.items():
    print(f"\nè®­ç»ƒ {name}...")

    # è®­ç»ƒæ—¶é—´æµ‹é‡
    start_time = time.time()

    # äº¤å‰éªŒè¯
    cv_scores = cross_val_score(model, x_train, y_train, cv=5, scoring='accuracy')

    # è®­ç»ƒå®Œæ•´æ¨¡å‹
    model.fit(x_train, y_train)

    training_time = time.time() - start_time

    # é¢„æµ‹
    y_pred = model.predict(x_test)
    test_accuracy = (y_pred == y_test).mean()

    # å­˜å‚¨ç»“æœ
    results[name] = {
        'cv_neam': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'test_accuracy': test_accuracy,
        'model': model
    }
    traning_times[name] = training_time

    print(f"  äº¤å‰éªŒè¯å‡†ç¡®ç‡: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
    print(f"  æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy:.4f}")
    print(f"  è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")

print("\nğŸ“Š === æ¨¡å‹æ€§èƒ½å¯¹æ¯” ===")