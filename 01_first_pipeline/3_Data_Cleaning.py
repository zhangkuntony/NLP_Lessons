# æ•°æ®æ¸…ç†å’Œé¢„å¤„ç†å®æˆ˜ä»£ç 
import re
import pandas as pd
import jieba

# æ¨¡æ‹Ÿæ™ºèƒ½å®¢æœçš„åŸå§‹æ•°æ®ï¼ˆåŒ…å«å„ç§é—®é¢˜ï¼‰
raw_data = [
    {"text": "æ€ä¹ˆé€€æ¬¾ï¼Ÿ", "intent": "é€€æ¬¾å’¨è¯¢"},
    {"text": "", "intent": ""},  # ç©ºæ–‡æœ¬
    {"text": "æˆ‘çš„è®¢å•ä»€ä¹ˆæ—¶å€™å‘è´§ï¼Ÿï¼Ÿï¼Ÿ", "intent": "ç‰©æµæŸ¥è¯¢"},
    {"text": "    æœ‰ä»€ä¹ˆä¼˜æƒ æ´»åŠ¨å—   ", "intent": "ä¼˜æƒ å’¨è¯¢"},  # å¤šä½™ç©ºæ ¼
    {"text": "äº§å“è´¨é‡æœ‰é—®é¢˜ï¼Œè¦æ±‚é€€è´§ï¼ï¼ï¼", "intent": "å”®åæŠ•è¯‰"},
    {"text": "å®¢æœç”µè¯å¤šå°‘ 13812345678", "intent": "è”ç³»æ–¹å¼"},  # åŒ…å«æ‰‹æœºå·
    {"text": "æ€ä¹ˆé€€æ¬¾ï¼Ÿ", "intent": "é€€æ¬¾å’¨è¯¢"},  # é‡å¤æ•°æ®
    {"text": "è®¿é—® https://www.example.com äº†è§£æ›´å¤š", "intent": "å…¶ä»–"},  # åŒ…å«ç½‘å€
    {"text": "###@@!!!", "intent": "--++"},  # çº¯ç¬¦å·
    {"text": "èƒ½ä¸èƒ½æ¢è´§å‘¢ï¼ŸğŸ¤”", "intent": "æ¢è´§å’¨è¯¢"},  # åŒ…å«emoji
]

df_raw = pd.DataFrame(raw_data)

print("ğŸ” === åŸå§‹æ•°æ®æ¦‚è§ˆ ===")
print(f"åŸå§‹æ•°æ®é‡: {len(df_raw)} æ¡")
print("æ ·æœ¬æ•°æ®:")
for idx, (i, row) in enumerate(df_raw.iterrows()):
    print(f"    {idx+1}. '{row['text']}' -> {row['intent']}")

print("\nğŸ§¹ === å¼€å§‹æ•°æ®æ¸…ç† ===")

# æ­¥éª¤1ï¼šåˆ é™¤ç©ºæ–‡æœ¬å’Œç©ºæ ‡ç­¾
print("æ­¥éª¤1ï¼šåˆ é™¤ç©ºæ•°æ®")
df_clean = df_raw[
    (df_raw['text'].str.strip() != '') &
    (df_raw['intent'].str.strip() != '')
].copy()
print(f"åˆ é™¤ç©ºæ•°æ®åï¼š{len(df_clean)}æ¡")

# æ­¥éª¤2ï¼šåˆ é™¤é‡å¤æ•°æ®
print("æ­¥éª¤2ï¼šåˆ é™¤é‡å¤æ•°æ®")
before_dedup = len(df_clean)
df_clean = df_clean.drop_duplicates(subset=['text', 'intent'])
print(f"åˆ é™¤é‡å¤åï¼š{len(df_clean)} æ¡ ï¼ˆåˆ é™¤äº†{before_dedup - len(df_clean)}æ¡é‡å¤æ•°æ®ï¼‰")

# æ­¥éª¤3ï¼šåˆ é™¤çº¯ç¬¦å·æ–‡æœ¬
print("æ­¥éª¤3ï¼šåˆ é™¤çº¯ç¬¦å·æ–‡æœ¬")
def is_valid_text(text):
    # å»é™¤æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼åï¼Œæ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœ‰æ•ˆå­—ç¬¦
    replaced_text = re.sub(r'[^\w\s]', '', text.strip())
    return len(replaced_text) >= 2

df_clean = df_clean[df_clean['text'].apply(is_valid_text)]
print(f"åˆ é™¤çº¯ç¬¦å·åï¼š {len(df_clean)} æ¡")

# æ­¥éª¤4ï¼šæ–‡æœ¬æ¸…ç†å‡½æ•°
def clean_text(text):
    """æ–‡æœ¬æ¸…ç†å‡½æ•°"""
    if pd.isna(text):
        return ""

    text = str(text)

    # å»é™¤ç½‘å€
    text = re.sub(r'https?://\S+', '', text)

    # å»é™¤é‚®ç®±
    text = re.sub(r'\S+@\S+\.\S+', '', text)

    # å»é™¤æ‰‹æœºå·ç ï¼ˆç®€å•è§„åˆ™ï¼‰
    text = re.sub(r'1[3-9]\d{9}', '[æ‰‹æœºå·]', text)

    # å»é™¤å¤šä½™çš„æ ‡ç‚¹ç¬¦å·
    text = re.sub(r'([ï¼ï¼Ÿã€‚ï¼Œ])\1+', r'\1', text)  # å¤šä¸ªæ ‡ç‚¹å˜ä¸€ä¸ª

    # å»é™¤emojiï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
    text = re.sub(r'[ğŸ€€-ğŸ¿¿]', '', text)

    # å»é™¤å¤šä½™ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text).strip()

    return text

print("æ­¥éª¤4ï¼šåº”ç”¨æ–‡æœ¬æ¸…ç†")
df_clean['text'] = df_clean['text'].apply(clean_text)

# å†æ¬¡æ£€æŸ¥é•¿åº¦
df_clean = df_clean[df_clean['text'].str.len() >= 2]
print(f"æœ€ç»ˆæ¸…ç†åï¼š{len(df_clean)} æ¡")

print("\nğŸ“Š === æ¸…ç†ç»“æœå¯¹æ¯” ===")
print("æ¸…ç†å‰ vs æ¸…ç†å:")
for i, (orig, clean) in enumerate(zip(df_raw['text'][:5], df_clean['text'][:5])):
    print(f"{i+1}. åŸå§‹: '{orig}'")
    print(f"   æ¸…ç†: '{clean}'")
    print()

# æ­¥éª¤5ï¼šä¸­æ–‡åˆ†è¯å¤„ç†
print("ğŸ“ === åˆ†è¯å¤„ç† ===")

# åŠ è½½åœç”¨è¯ï¼ˆè¿™é‡Œç”¨ç®€å•çš„åœç”¨è¯åˆ—è¡¨ï¼‰
stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°',
              'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}

def tokenize_text(text):
    """ä¸­æ–‡åˆ†è¯"""
    words = jieba.lcut(text)
    # å»é™¤åœç”¨è¯å’Œæ ‡ç‚¹
    words = [w for w in words if w not in stop_words and len(w.strip()) > 1 and not re.match(r'\W', w)]
    return words

# ä¸ºæ–‡æœ¬æ·»åŠ åˆ†è¯ç»“æœ
df_clean['tokens'] = df_clean['text'].apply(tokenize_text)

print("åˆ†è¯ç»“æœç¤ºä¾‹ï¼š")
for i, row in df_clean.iterrows():
    print(f"åŸæ–‡ï¼š{row['text']}")
    print(f"åˆ†è¯ï¼š{row['tokens']}")
    print()

print("âœ… === æ•°æ®æ¸…ç†å®Œæˆ ===")
print(f"ğŸ“Š åŸå§‹æ•°æ®: {len(df_raw)} æ¡")
print(f"ğŸ“Š æ¸…ç†å: {len(df_clean)} æ¡")
print(f"ğŸ“Š æ¸…ç†ç‡: {(len(df_raw) - len(df_clean))/len(df_raw)*100:.1f}%")

# ä¿å­˜æ¸…ç†åçš„æ•°æ®
print("\nğŸ’¾ æ•°æ®æ¸…ç†æ€»ç»“:")
print("âœ… åˆ é™¤äº†ç©ºæ–‡æœ¬å’Œæ— æ•ˆæ•°æ®")
print("âœ… å»é™¤äº†é‡å¤æ•°æ®")
print("âœ… æ¸…ç†äº†ç½‘å€ã€æ‰‹æœºå·ç­‰æ•æ„Ÿä¿¡æ¯")
print("âœ… ç»Ÿä¸€äº†æ ‡ç‚¹ç¬¦å·æ ¼å¼")
print("âœ… å®Œæˆäº†ä¸­æ–‡åˆ†è¯")
print("âœ… æ•°æ®å·²å‡†å¤‡å¥½è¿›å…¥ä¸‹ä¸€æ­¥ï¼")




