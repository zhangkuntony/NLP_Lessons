import requests
from bs4 import BeautifulSoup

# ç¤ºä¾‹1. ä»ç½‘é¡µä¸­æŠ½å–æ–‡æœ¬ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
def extract_text_from_url(url, timeout=10):
    """ä»URLæå–æ–‡æœ¬å†…å®¹"""
    try:
        # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, timeout=timeout, headers=headers)
        response.raise_for_status()
        
        # æ£€æµ‹å¹¶è®¾ç½®ç¼–ç 
        response.encoding = response.apparent_encoding
        
        soup_text = BeautifulSoup(response.text, 'html.parser')

        # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
        for script in soup_text(["script", "style"]):
            script.decompose()

        # æå–æ–‡æœ¬
        text_from_url = soup_text.get_text()

        # æ¸…ç†ç©ºç™½å­—ç¬¦
        lines = (line.strip() for line in text_from_url.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text_from_url = ' '.join(chunk for chunk in chunks if chunk)

        return text_from_url

    except requests.RequestException as e:
        print(f"ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼š{e}")
        return None

print("ä»ç½‘é¡µæå–æ–‡å­—ï¼š")
# web_page_text = extract_text_from_url("https://export.shobserver.com/baijiahao/html/1022224.html", 30)
web_page_text = extract_text_from_url("https://finance.sina.com.cn/money/nmetal/roll/2025-11-20/doc-infxzkva3855674.shtml", 30)
print(web_page_text)

# ç¤ºä¾‹2. ä½¿ç”¨æœ¬åœ°HTMLæ–‡ä»¶ï¼ˆæ›´ç¨³å®šçš„ç¤ºä¾‹ï¼‰
sample_html = """
<html>
<head><title>ç¤ºä¾‹ç½‘é¡µ</title></head>
<body>
    <h1>è‡ªç„¶è¯­è¨€å¤„ç†æ•™ç¨‹</h1>
    <p>è¿™æ˜¯ä¸€ä¸ªå…³äºNLPçš„æ•™ç¨‹ï¼Œæ¶µç›–äº†ä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´æµç¨‹ã€‚</p>
    <p>åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦ä»ç½‘é¡µã€æ–‡æ¡£ç­‰å¤šç§æ¥æºæå–æ–‡æœ¬ä¿¡æ¯ã€‚</p>
    <div class="ad">è¿™æ˜¯å¹¿å‘Šå†…å®¹ï¼Œé€šå¸¸éœ€è¦è¿‡æ»¤æ‰</div>
    <p>æ–‡æœ¬æ¸…ç†æ˜¯NLP pipelineä¸­çš„é‡è¦ç¯èŠ‚ã€‚</p>
</body>
</html>
"""

soup = BeautifulSoup(sample_html, 'html.parser')

# ç§»é™¤å¹¿å‘Šç­‰æ— å…³å†…å®¹
for ad in soup.find_all('div', class_='ad'):
    ad.decompose()

# æå–æ®µè½æ–‡æœ¬
paragraphs = soup.find_all('p')
print("æå–åˆ°çš„æ®µè½æ–‡æœ¬")
for i, p in enumerate(paragraphs, 1):
    print(f"{i}. {p.get_text()}")

# æå–æ‰€æœ‰æ–‡æœ¬
all_text = soup.get_text()
# æ‰‹åŠ¨æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
all_text = ' '.join(all_text.split())
print(f"\nå®Œæ•´æ–‡æœ¬ï¼š\n{all_text}")

# Unicode æ ‡å‡†åŒ–
text = "I feel really ğŸ˜¡. GOGOGO!! ğŸ’ªğŸ’ªğŸ’ª  ğŸ¤£ğŸ¤£ È€Ã†ÄÇ¦Æ“"
print(text)
text2 = text.encode("utf-8")  # encode the strings in bytes
print(text2)

# åˆ†æ®µå’Œåˆ†è¯
# éœ€è¦å…ˆä¸‹è½½NLTKæ•°æ®
import nltk
nltk.download('punkt_tab')  # å–æ¶ˆæ³¨é‡Šä»¥ä¸‹è½½åˆ†è¯æ¨¡å‹

from nltk.tokenize import sent_tokenize, word_tokenize

# è‹±æ–‡æ–‡æœ¬ç¤ºä¾‹
english_text = """
Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.
"""

print("=== è‹±æ–‡æ–‡æœ¬å¤„ç† ===")
## å¥å­åˆ†å‰²
sents = sent_tokenize(english_text)

## è¯æ±‡åˆ†å‰²
for i, sent in enumerate(sents, 1):
    print(f"å¥å­ {i}: {sent.strip()}")
    print(f"åˆ†è¯ç»“æœ: {word_tokenize(sent)}")
    print()

# ä¸­æ–‡æ–‡æœ¬å¤„ç†ç¤ºä¾‹
print("=== ä¸­æ–‡æ–‡æœ¬å¤„ç† ===")
chinese_text = "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ã€‚å®ƒç ”ç©¶å¦‚ä½•è®©è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚ä¸­æ–‡åˆ†è¯æ˜¯ä¸­æ–‡NLPçš„åŸºç¡€ä»»åŠ¡ã€‚"

# æ–¹æ³•1ï¼šç®€å•çš„ä¸­æ–‡å¥å­åˆ†å‰²
chinese_sentences = chinese_text.split('ã€‚')
chinese_sentences = [s.strip() for s in chinese_sentences if s.strip()]

print("ä¸­æ–‡å¥å­åˆ†å‰²:")
for i, sent in enumerate(chinese_sentences, 1):
    print(f"å¥å­ {i}: {sent}")

print("\nä¸­æ–‡å­—ç¬¦çº§åˆ†å‰²:")
print(list(chinese_text))

# æ¨èä½¿ç”¨ä¸“é—¨çš„ä¸­æ–‡åˆ†è¯å·¥å…·
print("\næ³¨æ„ï¼šä¸­æ–‡åˆ†è¯å»ºè®®ä½¿ç”¨ä¸“é—¨å·¥å…·å¦‚jiebaã€pkusegç­‰")
print("ç¤ºä¾‹ï¼špip install jieba")

import jieba
try:
    print("jiebaåˆ†è¯ç»“æœ:")
    words = jieba.lcut(chinese_text)
    print(words)
except ImportError:
    print("jiebaæœªå®‰è£…ï¼Œå¯ä»¥è¿è¡Œ: pip install jieba")
