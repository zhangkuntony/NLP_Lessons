import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œemojiå…¼å®¹å­—ä½“
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def simple_attention_demo():
    """
    ç®€å•çš„æ³¨æ„åŠ›æœºåˆ¶æ¼”ç¤º - ä¸ä½¿ç”¨å¯å­¦ä¹ å‚æ•°
    é€šè¿‡ç›´æ¥çš„å‘é‡ç›¸ä¼¼åº¦è®¡ç®—æ¥ç†è§£æ³¨æ„åŠ›
    """
    print("=== ğŸ¯ ç®€å•æ³¨æ„åŠ›æœºåˆ¶æ¼”ç¤º ===\n")

    # ä½¿ç”¨ç®€å•çš„è¯å‘é‡è¡¨ç¤ºï¼ˆä¸æ¶‰åŠå¯å­¦ä¹ å‚æ•°ï¼‰
    sentence = "å°æ˜å–œæ¬¢è‹¹æœ"
    words = ['å°æ˜', 'å–œæ¬¢', 'è‹¹æœ']

    # æ‰‹å·¥è®¾è®¡çš„è¯å‘é‡ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰
    # ç»´åº¦å«ä¹‰ï¼š[äººç‰©ï¼ŒåŠ¨ä½œï¼Œç‰©ä½“]
    word_vectors = {
        'å°æ˜': [1, 0, 0],            # çº¯äººç‰©
        'å–œæ¬¢': [0, 1, 0],            # çº¯åŠ¨ä½œ
        'è‹¹æœ': [0, 0, 1]             # çº¯ç‰©ä½“
    }

    print(f"å¥å­: {sentence}")
    print(f"è¯è¯­: {words}")
    print("\nè¯å‘é‡è¡¨ç¤ºï¼ˆäººç‰©, åŠ¨ä½œ, ç‰©ä½“ï¼‰:")
    for word in words:
        print(f"  {word}: {word_vectors[word]}")

    # è®¡ç®—æ³¨æ„åŠ›æƒé‡
    print("\n=== è®¡ç®—æ³¨æ„åŠ›è¿‡ç¨‹ ===")

    # å‡è®¾æˆ‘ä»¬è¦åˆ†æ"å–œæ¬¢"è¿™ä¸ªè¯
    query_word = "å–œæ¬¢"
    query_vector = np.array(word_vectors[query_word])

    print(f"\nğŸ” åˆ†æè¯è¯­: {query_word}")
    print(f"Queryå‘é‡: {query_vector}")

    # è®¡ç®—ä¸æ‰€æœ‰è¯çš„ç›¸ä¼¼åº¦
    similarities = []
    for word in words:
        word_vec = np.array(word_vectors[word])
        # ä½¿ç”¨ç‚¹ç§¯è®¡ç®—ç›¸ä¼¼åº¦
        similarity = np.dot(query_vector, word_vec)
        similarities.append(similarity)
        print(f"  ä¸'{word}'çš„ç›¸ä¼¼åº¦: {query_vector} Â· {word_vec} = {similarity}")

    # è½¬æ¢ä¸ºæ³¨æ„åŠ›æƒé‡
    similarities = np.array(similarities)
    attention_weights = np.exp(similarities) / np.sum(np.exp(similarities))

    print(f"\nğŸ“Š æ³¨æ„åŠ›æƒé‡:")
    for i, word in enumerate(words):
        print(f"  {word}: {attention_weights[i]:.3f}")

    print(f"\nâœ… æƒé‡æ€»å’Œ: {np.sum(attention_weights):.6f}")

    # åˆ†æç»“æœ
    print(f"\nğŸ§  ç»“æœåˆ†æ:")
    max_idx = np.argmax(attention_weights)
    print(f"  '{query_word}'æœ€å…³æ³¨çš„è¯æ˜¯: {words[max_idx]} (æƒé‡: {attention_weights[max_idx]:.3f})")

    return attention_weights, words

# æ‰§è¡Œæ¼”ç¤º
weights, words = simple_attention_demo()


# å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡
def visualize_attention_weights(weights, words, query_word="å–œæ¬¢"):
    """
    ä½¿ç”¨çƒ­åŠ›å›¾å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡
    """
    plt.figure(figsize=(12, 8))

    # åˆ›å»ºä¸€ä¸ª2x2çš„å­å›¾å¸ƒå±€

    # 1. æ¡å½¢å›¾ - æ˜¾ç¤ºæ³¨æ„åŠ›æƒé‡åˆ†å¸ƒ
    plt.subplot(2, 2, 1)
    colors = ['lightblue', 'lightcoral', 'lightgreen']
    bars = plt.bar(words, weights, color=colors, alpha=0.7, edgecolor='black')
    plt.title(f'"{query_word}"çš„æ³¨æ„åŠ›æƒé‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.ylabel('æ³¨æ„åŠ›æƒé‡')
    plt.xlabel('è¯è¯­')

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, weight in zip(bars, weights):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                 f'{weight:.3f}', ha='center', va='bottom', fontweight='bold')

    # 2. çƒ­åŠ›å›¾ - ä¸»è¦çš„å¯è§†åŒ–æ–¹å¼
    plt.subplot(2, 2, 2)
    weights_matrix = weights.reshape(1, -1)
    sns.heatmap(weights_matrix, annot=True, fmt='.3f',
                xticklabels=words, yticklabels=[f'æŸ¥è¯¢:{query_word}'],
                cmap='YlOrRd', cbar_kws={'label': 'æ³¨æ„åŠ›æƒé‡'},
                linewidths=0.5, linecolor='black')
    plt.title('æ³¨æ„åŠ›æƒé‡çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')

    # 3. é¥¼å›¾ - æ˜¾ç¤ºæ³¨æ„åŠ›åˆ†å¸ƒæ¯”ä¾‹
    plt.subplot(2, 2, 3)
    plt.pie(weights, labels=words, autopct='%1.1f%%', startangle=90,
            colors=colors, explode=[0.1 if w == max(weights) else 0 for w in weights])
    plt.title('æ³¨æ„åŠ›æƒé‡æ¯”ä¾‹', fontsize=14, fontweight='bold')

    # 4. è§£é‡Šè¯´æ˜
    plt.subplot(2, 2, 4)
    plt.axis('off')

    # åˆ›å»ºè§£é‡Šæ–‡æœ¬
    explanation_text = f"""
    æ³¨æ„åŠ›æƒé‡è§£é‡Šï¼š

    æŸ¥è¯¢è¯: "{query_word}"

    æƒé‡åˆ†æ:
    """

    for i, (word, weight) in enumerate(zip(words, weights)):
        explanation_text += f"\n  â€¢ {word}: {weight:.3f}"
        if weight == max(weights):
            explanation_text += " * (æœ€é«˜å…³æ³¨)"

    explanation_text += f"""

    ç†è§£ï¼š
    â€¢ æƒé‡è¶Šé«˜ï¼Œå…³æ³¨åº¦è¶Šå¤§
    â€¢ æ‰€æœ‰æƒé‡ä¹‹å’Œ = 1.0
    â€¢ çƒ­åŠ›å›¾é¢œè‰²è¶Šæ·±ï¼Œæƒé‡è¶Šé«˜
    """

    plt.text(0.05, 0.95, explanation_text, transform=plt.gca().transAxes,
             fontsize=10, verticalalignment='top',
             bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.8))

    plt.tight_layout()
    plt.show()

    # è¾“å‡ºé‡è¦ç»Ÿè®¡ä¿¡æ¯
    print("=== ğŸ“Š æ³¨æ„åŠ›æƒé‡ç»Ÿè®¡ ===")
    print(f"æœ€é«˜å…³æ³¨è¯: {words[np.argmax(weights)]} (æƒé‡: {max(weights):.3f})")
    print(f"æœ€ä½å…³æ³¨è¯: {words[np.argmin(weights)]} (æƒé‡: {min(weights):.3f})")
    print(f"æƒé‡æ€»å’Œ: {np.sum(weights):.6f}")


# å¯è§†åŒ–ç»“æœ
visualize_attention_weights(weights, words, query_word="å–œæ¬¢")


### ğŸ§® ç®€åŒ–ç‰ˆè‡ªæ³¨æ„åŠ›è®¡ç®—

def simple_self_attention_demo():
    """
    ç”¨æœ€ç®€å•çš„æ–¹å¼æ¼”ç¤ºè‡ªæ³¨æ„åŠ›è®¡ç®—
    ä¸æ¶‰åŠå¤æ‚çš„å¯å­¦ä¹ å‚æ•°ï¼Œä¸“æ³¨äºç†è§£æ ¸å¿ƒæ€æƒ³
    """
    print("=== ğŸ¯ åŠ¨æ‰‹è®¡ç®—è‡ªæ³¨æ„åŠ› ===\n")

    # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„å¥å­
    sentence = "å°æ˜å–œæ¬¢è‹¹æœ"
    words = ['å°æ˜', 'å–œæ¬¢', 'è‹¹æœ']

    print(f"å¥å­: {sentence}")
    print(f"è¯è¯­: {words}")

    # ç®€åŒ–çš„è¯å‘é‡è¡¨ç¤ºï¼ˆæ‰‹å·¥è®¾è®¡ï¼Œä¸æ˜¯å­¦ä¹ å¾—åˆ°çš„ï¼‰
    # æ¯ä¸ªè¯ç”¨3ç»´å‘é‡è¡¨ç¤º: [äººç‰©ç‰¹å¾, åŠ¨ä½œç‰¹å¾, ç‰©ä½“ç‰¹å¾]
    word_vectors = np.array([
        [1.0, 0.0, 0.0],        # å°æ˜: çº¯äººç‰©
        [0.2, 1.0, 0.2],        # å–œæ¬¢: ä¸»è¦æ˜¯åŠ¨ä½œï¼Œä½†ä¹Ÿæ¶‰åŠäººç‰©å’Œç‰©ä½“
        [0.0, 0.0, 1.0]         # è‹¹æœ: çº¯ç‰©ä½“
    ])

    print("\nè¯å‘é‡è¡¨ç¤º [äººç‰©, åŠ¨ä½œ, ç‰©ä½“]:")
    for i, word in enumerate(words):
        print(f"  {word}: {word_vectors[i]}")

    print("\n=== è‡ªæ³¨æ„åŠ›è®¡ç®—è¿‡ç¨‹ ===")

    # åœ¨è‡ªæ³¨æ„åŠ›ä¸­ï¼Œæ¯ä¸ªè¯éƒ½ä¼šå…³æ³¨æ‰€æœ‰è¯ï¼ˆåŒ…æ‹¬è‡ªå·±ï¼‰
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šç›´æ¥ä½¿ç”¨è¯å‘é‡ä½œä¸ºQã€Kã€V
    Q = word_vectors                # æŸ¥è¯¢çŸ©é˜µ
    K = word_vectors                # é”®çŸ©é˜µ
    V = word_vectors                # å€¼çŸ©é˜µ

    print("\n1. ğŸ“Š è®¡ç®—æ³¨æ„åŠ›å¾—åˆ†çŸ©é˜µ")
    # è®¡ç®—æ³¨æ„åŠ›å¾—åˆ†ï¼šQ @ K^T
    attention_scores = Q @ K.T
    print("æ³¨æ„åŠ›å¾—åˆ†çŸ©é˜µ (Q @ K^T):")
    print(f"{'':>6}", end="")
    for word in words:
        print(f"{word:>8}", end="")
    print()

    for i, query_word in enumerate(words):
        print(f"{query_word:>6}", end="")
        for j, key_word in enumerate(words):
            score = attention_scores[i, j]
            print(f"{score:>7.2f}", end="")
        print()

    print("\n2. ğŸ¯ åº”ç”¨Softmaxå¾—åˆ°æ³¨æ„åŠ›æƒé‡")
    # åº”ç”¨softmax
    attention_weights = np.exp(attention_scores) / np.sum(np.exp(attention_scores), axis=1, keepdims=True)

    print("æ³¨æ„åŠ›æƒé‡çŸ©é˜µ (æ¯è¡Œå’Œä¸º1):")
    print(f"{'':>6}", end="")
    for word in words:
        print(f"{word:>8}", end="")
    print()

    for i, query_word in enumerate(words):
        print(f"{query_word:>6}", end="")
        for j, key_word in enumerate(words):
            weight = attention_weights[i, j]
            print(f"{weight:>7.3f}", end="")
        print(f"  (å’Œ:{np.sum(attention_weights[i]):.3f})")

    print("\n3. ğŸ§  åˆ†ææ³¨æ„åŠ›æ¨¡å¼")
    for i, query_word in enumerate(words):
        max_attention_idx = np.argmax(attention_weights[i])
        max_attention_word = words[max_attention_idx]
        max_attention_weight = attention_weights[i, max_attention_idx]

        print(f"  '{query_word}' æœ€å…³æ³¨: '{max_attention_word}' (æƒé‡: {max_attention_weight:.3f})")

    print("\n4. ğŸ¯ è®¡ç®—æœ€ç»ˆè¾“å‡º")
    # è®¡ç®—æœ€ç»ˆè¾“å‡ºï¼šattention_weights @ V
    output = attention_weights @ V

    print("æœ€ç»ˆè¾“å‡º (æ¯ä¸ªè¯çš„æ–°è¡¨ç¤º):")
    for i, word in enumerate(words):
        print(f"  {word}: {output[i]}")

    print("\nğŸ’¡ å…³é”®æ´å¯Ÿ:")
    print("â€¢ æ¯ä¸ªè¯éƒ½èƒ½'çœ‹åˆ°'æ•´ä¸ªå¥å­çš„ä¿¡æ¯")
    print("â€¢ æ³¨æ„åŠ›æƒé‡å†³å®šäº†è¯è¯­ä¹‹é—´çš„å…³è”å¼ºåº¦")
    print("â€¢ è¾“å‡ºæ˜¯æ‰€æœ‰è¯ä¿¡æ¯çš„åŠ æƒèåˆ")
    print("â€¢ è¿™å°±æ˜¯è‡ªæ³¨æ„åŠ›çš„é­”æ³•ï¼")

    return attention_weights, words


# æ‰§è¡Œæ¼”ç¤º
attention_matrix, words = simple_self_attention_demo()


# å¯è§†åŒ–è‡ªæ³¨æ„åŠ›æƒé‡çŸ©é˜µ
def visualize_self_attention(attention_matrix, words):
    plt.figure(figsize=(12, 5))

    # çƒ­åŠ›å›¾
    plt.subplot(1, 2, 1)
    sns.heatmap(attention_matrix,
                annot=True,
                fmt='.3f',
                xticklabels=words,
                yticklabels=words,
                cmap='Blues',
                cbar_kws={'label': 'æ³¨æ„åŠ›æƒé‡'})
    plt.title('è‡ªæ³¨æ„åŠ›æƒé‡çŸ©é˜µ')
    plt.xlabel('é”®ä½ç½® (è¢«å…³æ³¨çš„ä½ç½®)')
    plt.ylabel('æŸ¥è¯¢ä½ç½® (å…³æ³¨çš„ä½ç½®)')

    # æ¯ä¸ªä½ç½®çš„æ³¨æ„åŠ›åˆ†å¸ƒ
    plt.subplot(1, 2, 2)
    x_pos = np.arange(len(words))
    width = 0.25

    for i, query_word in enumerate(words):
        plt.bar(x_pos + i * width, attention_matrix[i],
                width, label=f'æŸ¥è¯¢: {query_word}', alpha=0.7)

    plt.xlabel('é”®ä½ç½®')
    plt.ylabel('æ³¨æ„åŠ›æƒé‡')
    plt.title('å„ä½ç½®çš„æ³¨æ„åŠ›åˆ†å¸ƒ')
    plt.xticks(x_pos + width, words)
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()


# å¯è§†åŒ–ç»“æœ
visualize_self_attention(attention_matrix, words)


# å¯è§†åŒ–è‡ªæ³¨æ„åŠ›åœ¨ä»£è¯æŒ‡ä»£æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›
def visualize_pronoun_resolution():
    plt.figure(figsize=(15, 10))

    # ä½¿ç”¨ä¼˜åŒ–åçš„æ³¨æ„åŠ›çŸ©é˜µï¼ˆé‡æ–°å®šä¹‰ä»¥ç¡®ä¿å¯ç”¨æ€§ï¼‰
    sentence = "å°æ˜å–œæ¬¢è‹¹æœï¼Œä»–æ¯å¤©éƒ½åƒã€‚"
    words = ['å°æ˜', 'å–œæ¬¢', 'è‹¹æœ', 'ä»–', 'æ¯å¤©', 'éƒ½', 'åƒ']

    # é‡æ–°å®šä¹‰æ³¨æ„åŠ›æƒé‡çŸ©é˜µ
    attention_matrix = np.array([
        [0.7, 0.1, 0.1, 0.05, 0.02, 0.01, 0.02],  # å°æ˜ -> ä¸»è¦å…³æ³¨è‡ªå·±
        [0.3, 0.4, 0.2, 0.05, 0.02, 0.01, 0.02],  # å–œæ¬¢ -> å…³æ³¨ä¸»è¯­å’Œå®¾è¯­
        [0.1, 0.2, 0.6, 0.05, 0.02, 0.01, 0.02],  # è‹¹æœ -> ä¸»è¦å…³æ³¨è‡ªå·±
        [0.8, 0.05, 0.05, 0.05, 0.02, 0.01, 0.02],  # ä»– -> é«˜åº¦å…³æ³¨"å°æ˜"ï¼
        [0.1, 0.1, 0.1, 0.1, 0.5, 0.1, 0.1],  # æ¯å¤© -> å…³æ³¨æ—¶é—´ç›¸å…³
        [0.1, 0.1, 0.1, 0.1, 0.3, 0.2, 0.1],  # éƒ½ -> å…³æ³¨åŠ¨ä½œç›¸å…³
        [0.2, 0.3, 0.2, 0.1, 0.1, 0.05, 0.05]  # åƒ -> å…³æ³¨ä¸»è¯­ã€åŠ¨ä½œå’Œå®¾è¯­
    ])

    # åˆ›å»ºä¸‰ä¸ªå­å›¾æ¥å±•ç¤ºä¸åŒçš„è§†è§’

    # 1. æ³¨æ„åŠ›æƒé‡çƒ­åŠ›å›¾
    plt.subplot(2, 2, 1)
    sns.heatmap(attention_matrix,
                annot=True,
                fmt='.2f',
                xticklabels=words,
                yticklabels=words,
                cmap='Reds',
                cbar_kws={'label': 'æ³¨æ„åŠ›æƒé‡'})
    plt.title('è‡ªæ³¨æ„åŠ›æƒé‡çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')
    plt.xlabel('è¢«å…³æ³¨çš„è¯')
    plt.ylabel('æŸ¥è¯¢è¯')

    # 2. ä»£è¯"ä»–"çš„æ³¨æ„åŠ›åˆ†å¸ƒ
    plt.subplot(2, 2, 2)
    pronoun_attention = attention_matrix[3]  # "ä»–"çš„æ³¨æ„åŠ›åˆ†å¸ƒ
    bars = plt.bar(words, pronoun_attention,
                   color=['red' if w == 'å°æ˜' else 'lightblue' for w in words],
                   alpha=0.8)
    plt.title('ä»£è¯"ä»–"çš„æ³¨æ„åŠ›åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.ylabel('æ³¨æ„åŠ›æƒé‡')
    plt.xticks(rotation=45)

    # é«˜äº®æœ€é«˜æƒé‡
    max_idx = np.argmax(pronoun_attention)
    bars[max_idx].set_color('red')
    bars[max_idx].set_alpha(1.0)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, weight) in enumerate(zip(bars, pronoun_attention)):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                 f'{weight:.2f}', ha='center', va='bottom', fontweight='bold')

    # 3. åŠ¨è¯"å–œæ¬¢"çš„æ³¨æ„åŠ›åˆ†å¸ƒ
    plt.subplot(2, 2, 3)
    verb_attention = attention_matrix[1]  # "å–œæ¬¢"çš„æ³¨æ„åŠ›åˆ†å¸ƒ
    bars2 = plt.bar(words, verb_attention,
                    color=['orange' if w in ['å°æ˜', 'è‹¹æœ'] else 'lightgray' for w in words],
                    alpha=0.8)
    plt.title('åŠ¨è¯"å–œæ¬¢"çš„æ³¨æ„åŠ›åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.ylabel('æ³¨æ„åŠ›æƒé‡')
    plt.xticks(rotation=45)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, weight) in enumerate(zip(bars2, verb_attention)):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                 f'{weight:.2f}', ha='center', va='bottom', fontweight='bold')

    # 4. æ³¨æ„åŠ›æµå‘å›¾
    plt.subplot(2, 2, 4)
    # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„æ³¨æ„åŠ›æµå‘å¯è§†åŒ–
    pos_y = np.arange(len(words))

    # ç»˜åˆ¶è¯è¯­
    for i, word in enumerate(words):
        if word == 'ä»–':
            plt.text(0, i, word, fontsize=16, fontweight='bold',
                     ha='center', va='center',
                     bbox=dict(boxstyle="round,pad=0.3", facecolor='red', alpha=0.7))
        elif word == 'å°æ˜':
            plt.text(0, i, word, fontsize=16, fontweight='bold',
                     ha='center', va='center',
                     bbox=dict(boxstyle="round,pad=0.3", facecolor='orange', alpha=0.7))
        else:
            plt.text(0, i, word, fontsize=14,
                     ha='center', va='center',
                     bbox=dict(boxstyle="round,pad=0.3", facecolor='lightblue', alpha=0.7))

    # ç»˜åˆ¶"ä»–"åˆ°"å°æ˜"çš„å¼ºè¿æ¥
    he_idx = words.index('ä»–')
    ming_idx = words.index('å°æ˜')

    plt.arrow(0.1, he_idx, 0, ming_idx - he_idx - 0.1,
              head_width=0.05, head_length=0.1,
              fc='red', ec='red', linewidth=3, alpha=0.8)

    plt.text(0.2, (he_idx + ming_idx) / 2, '0.80',
             fontsize=12, fontweight='bold', color='red')

    plt.xlim(-0.3, 0.4)
    plt.ylim(-0.5, len(words) - 0.5)
    plt.title('ä»£è¯æŒ‡ä»£å…³ç³»å¯è§†åŒ–', fontsize=14, fontweight='bold')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

    # è¾“å‡ºè§£é‡Š
    print("\nğŸ¯ è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å¼ºå¤§èƒ½åŠ›å±•ç¤º:")
    print("=" * 50)
    print("1. ä»£è¯è§£æ: 'ä»–' â†’ 'å°æ˜' (æƒé‡: 0.80)")
    print("   è‡ªæ³¨æ„åŠ›æˆåŠŸè¯†åˆ«å‡ºä»£è¯ä¸å…¶æŒ‡ä»£å¯¹è±¡çš„å…³ç³»")
    print()
    print("2. è¯­æ³•å…³ç³»: 'å–œæ¬¢' è¿æ¥ 'å°æ˜' å’Œ 'è‹¹æœ'")
    print("   åŠ¨è¯åŒæ—¶å…³æ³¨ä¸»è¯­å’Œå®¾è¯­ï¼Œä½“ç°è¯­æ³•ç»“æ„")
    print()
    print("3. è¯­ä¹‰è”ç³»: 'åƒ' å…³æ³¨ç›¸å…³å®ä½“")
    print("   åŠ¨ä½œè¯å…³æ³¨æ‰§è¡Œè€…ã€å¯¹è±¡å’Œç›¸å…³åŠ¨ä½œ")
    print()
    print("è¿™äº›ä¾‹å­å±•ç¤ºäº†è‡ªæ³¨æ„åŠ›æœºåˆ¶åœ¨ç†è§£è¯­è¨€ç»“æ„ã€")
    print("å»ºç«‹è¯è¯­å…³ç³»æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ï¼")


# æ‰§è¡Œå¯è§†åŒ–
visualize_pronoun_resolution()



